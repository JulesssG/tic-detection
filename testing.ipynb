{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "from time import time\n",
    "from sklearn.decomposition import IncrementalPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def read_video(filename, nframes=np.inf):\n",
    "    \"\"\"\n",
    "        Read the given number of frames of a video using \n",
    "        the opencv library\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(filename)\n",
    "    fps = round(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    i = 0\n",
    "    while cap.isOpened() and i < nframes:\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frames.append(frame)\n",
    "            i += 1\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    return np.array(frames), fps, width, height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video loading...\n",
      "Loaded video of 20.0 seconds with quality 960x540 in 1.13 seconds\n",
      "Transforming the video...\n",
      "Fitting of the pca model took 124.42 seconds\n",
      "Transformations of the videos took 2.3 seconds\n",
      "Displaying and writting the video...\n"
     ]
    }
   ],
   "source": [
    "print('Video loading...')\n",
    "# Read the video\n",
    "start = time()\n",
    "sample_name = 'sample20s_540'\n",
    "frames, fps, width, height = read_video('data/'+sample_name+'.mp4')\n",
    "nframes = frames.shape[0]\n",
    "print(f'Loaded video of {round(nframes/fps, 2)} seconds with quality {width}x{height} in {round(time()-start,2)} seconds')\n",
    "\n",
    "# Convert to gray scale\n",
    "print('Transforming the video...')\n",
    "gray_frames = np.zeros((nframes, height, width), dtype=np.uint8)\n",
    "for i, frame in enumerate(frames):\n",
    "    gray_frames[i] = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Create, fit and apply the pca model\n",
    "pca_model = IncrementalPCA(n_components=50)\n",
    "start = time()\n",
    "pca_model.fit(gray_frames.reshape(gray_frames.shape[0], -1))\n",
    "after_fit = time()\n",
    "reduced_gray_frames = pca_model.transform(gray_frames.reshape(gray_frames.shape[0], -1))\n",
    "gray_frames_2 = pca_model.inverse_transform(reduced_gray_frames).reshape((nframes, height, width))\n",
    "after_transformations = time()\n",
    "print(f'Fitting of the pca model took {round(after_fit-start,2)} seconds')\n",
    "print(f'Transformations of the videos took {round(after_transformations-after_fit,2)} seconds')\n",
    "\n",
    "# Write the videos to disk\n",
    "writer_after_pca = cv2.VideoWriter('data/'+sample_name+'_after_pca.mp4', cv2.VideoWriter_fourcc(*\"MJPG\"),\n",
    "                         fps, (width, height))\n",
    "writer_gray = cv2.VideoWriter('data/'+sample_name+'_gray.mp4', cv2.VideoWriter_fourcc(*\"MJPG\"),\n",
    "                         fps, (width, height), 0)\n",
    "writer_gray_after_pca = cv2.VideoWriter('data/'+sample_name+'_gray_after_pca.mp4', cv2.VideoWriter_fourcc(*\"MJPG\"),\n",
    "                         fps, (width, height), 0)\n",
    "print('Displaying and writting the video...')\n",
    "for i in range(nframes):\n",
    "    frame_pca = np.around(gray_frames_2[i]).astype(np.uint8)\n",
    "    writer_gray.write(gray_frames[i])\n",
    "    writer_gray_after_pca.write(frame_pca)\n",
    "    \n",
    "    cv2.imshow('Video Capture', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "    \n",
    "# When everything done, release the video capture and video write objects\n",
    "writer_after_pca.release()\n",
    "writer_gray.release()\n",
    "writer_gray_after_pca.release()\n",
    "\n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import linecache\n",
    "import csv\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\"\"\"\n",
    "    Code taken from https://discuss.pytorch.org/t/dataloaders-multiple-files-and-multiple-rows-per-column-with-lazy-evaluation/11769/8\n",
    "\"\"\"\n",
    "\n",
    "class LazyTextDataset(Dataset):\n",
    "    def __init__(self, filename):\n",
    "        self._filename = filename\n",
    "        self._total_data = int(subprocess.check_output(\"wc -l \" + filename, shell=True).split()[0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        line = linecache.getline(self._filename, idx + 1)\n",
    "        csv_line = csv.reader([line])\n",
    "        return next(csv_line)\n",
    "      \n",
    "    def __len__(self):\n",
    "        return self._total_data\n",
    "\n",
    "path = 'data/test/'\n",
    "files = list(map(lambda x : path + x, (filter(lambda x : x.endswith(\"csv\"), os.listdir(path)))))\n",
    "datasets = list(map(lambda x : LazyTextDataset(x), files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from video_loader import video_loader\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "\n",
    "videos = !ls data/sample*.mp4\n",
    "videos1 = videos[0:1]\n",
    "loader = video_loader(videos1, 20, create_batch=False)\n",
    "frames = loader.create_frames()\n",
    "frames = frames[0].unsqueeze(1).transpose(1, 4).squeeze()\n",
    "\n",
    "#frames = frames[:, :, :72, :128] #TEMP\n",
    "frames = frames.reshape(frames.shape[0], -1)\n",
    "\n",
    "batch = frames.split(100, 0)\n",
    "ncomp = 10\n",
    "pca_model1 = IncrementalPCA(n_components=ncomp)\n",
    "pca_model2 = IncrementalPCA(n_components=ncomp)\n",
    "\n",
    "for b in batch:\n",
    "    pca_model1.partial_fit(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120, 720, 1280, 3])\n",
      "torch.Size([121, 720, 1280, 3])\n",
      "torch.Size([121, 720, 1280, 3])\n",
      "torch.Size([121, 720, 1280, 3])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import IncrementalPCA\n",
    "from torchvision.io import read_video\n",
    "\n",
    "# NFRAMES x WIDTH x HEIGHT x CHANNElS\n",
    "ncomp = 10\n",
    "filename = 'data/sample1.mp4'\n",
    "pca_model = IncrementalPCA(n_components=ncomp)\n",
    "for start in range(0, 16, 5):\n",
    "    vframes = read_video(filename, start_pts=start, end_pts=start+5, pts_unit='sec')[0]\n",
    "    print(vframes.shape)\n",
    "    vframes = vframes.reshape(vframes.shape[0], -1)\n",
    "    pca_model.partial_fit(vframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "partial_result = pca_model1.transform(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "full_result = pca_model2.fit_transform(frames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
