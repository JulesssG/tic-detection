{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "from time import time, sleep\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### SVD runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video loading...\n",
      "Loaded video of 20.0 seconds with quality 960x540 in 0.82 seconds\n",
      "Transforming the video...\n",
      "Fitting of the scipy SVD model took 20.05 seconds\n",
      "Fitting of the truncated SVD model took 22.52 seconds\n",
      "Fitting of the randomized SVD model took 18.98 seconds\n"
     ]
    }
   ],
   "source": [
    "# SVD comparison on 20s grayscale\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "print('Video loading...')\n",
    "# Read the video\n",
    "start = time()\n",
    "sample_name = 'sample20s_540'\n",
    "frames, fps, width, height = read_video('data_generated/'+sample_name+'.mp4')\n",
    "nframes = frames.shape[0]\n",
    "print(f'Loaded video of {round(nframes/fps, 2)} seconds with quality {width}x{height} in {round(time()-start,2)} seconds')\n",
    "\n",
    "# Convert to gray scale\n",
    "print('Transforming the video...')\n",
    "gray_frames = np.zeros((nframes, height, width), dtype=np.uint8)\n",
    "for i, frame in enumerate(frames):\n",
    "    gray_frames[i] = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Fit a SVD model\n",
    "start = time()\n",
    "u, s, vh = svds(gray_frames.reshape(gray_frames.shape[0], -1).astype(float), k=50)\n",
    "after_fit = time()\n",
    "after_transformations = time()\n",
    "print(f'Fitting of the scipy SVD model took {round(after_fit-start,2)} seconds')\n",
    "svd_model = TruncatedSVD(n_components=50)\n",
    "start = time()\n",
    "u, s, vh = svd_model.fit(gray_frames.reshape(gray_frames.shape[0], -1))\n",
    "after_fit = time()\n",
    "after_transformations = time()\n",
    "print(f'Fitting of the truncated SVD model took {round(after_fit-start,2)} seconds')\n",
    "start = time()\n",
    "u, s, vh = randomized_svd(gray_frames.reshape(gray_frames.shape[0], -1), 50)\n",
    "after_fit = time()\n",
    "after_transformations = time()\n",
    "print(f'Fitting of the randomized SVD model took {round(after_fit-start,2)} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Numpy's SVD -> MemoryError: Unable to allocate 1.96 TiB for an array with shape (518400, 518400) and data type float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### SVD -> PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "video = VideoLoader('data/sample20s.mp4', duration=60, grayscale=True, scale=(480, 270))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "pca_model = IncrementalPCA(n_components=10)\n",
    "pca_model2 = IncrementalPCA(n_components=10)\n",
    "all_frames = video.get_all_frames()\n",
    "original_shape = all_frames.shape\n",
    "mean, std = np.mean(all_frames), np.std(all_frames)\n",
    "all_frames_std = (all_frames -  mean) / std #???\n",
    "frames_after_pca = pca_model.inverse_transform(pca_model.fit_transform(all_frames.reshape(all_frames.shape[0], -1)))\n",
    "frames_after_pca = frames_after_pca.reshape(all_frames.shape)\n",
    "frames_after_pca2 = pca_model2.inverse_transform(pca_model2.fit_transform(all_frames_std.reshape(all_frames.shape[0], -1)))\n",
    "frames_after_pca2 = frames_after_pca2.reshape(all_frames_std.shape)\n",
    "frames_after_pca2 = (frames_after_pca2*std) + mean\n",
    "write_video('data/20pca.mp4', frames_after_pca, all_frames.shape[2], all_frames.shape[1], 24, grayscale=True)\n",
    "write_video('data/20pca_std.mp4', frames_after_pca2, all_frames.shape[2], all_frames.shape[1], 24, grayscale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.extmath import randomized_svd\n",
    "\n",
    "frames_svd = all_frames_std.reshape(all_frames.shape[0], -1)\n",
    "\n",
    "u, _, _ = randomized_svd(frames_svd.T, 10)\n",
    "proj = u.T @ frames_svd.T\n",
    "\n",
    "after_proj = (u @ proj).T\n",
    "after_proj = after_proj.reshape(all_frames.shape)\n",
    "after_proj = (after_proj*std)+mean\n",
    "write_video('data/20svd.mp4', after_proj, original_shape[2], original_shape[1], 24, grayscale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27.96268172632351, 27.9626817263235, 34.95518856158816)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(reconstruction_error(np.clip(frames_after_pca, 0, 255), all_frames), \n",
    " reconstruction_error(np.clip(frames_after_pca2, 0, 255), all_frames), \n",
    " reconstruction_error(np.clip(after_proj, 0, 255), all_frames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### PCA model using SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.95518856158816"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video = VideoLoader('data/sample20s.mp4', duration=60, grayscale=True, scale=(480, 270))\n",
    "\n",
    "frames = video.get_all_frames()\n",
    "\n",
    "pca_model = custom_pca(ncomp=10)\n",
    "pca_model.fit(frames)\n",
    "reduced = pca_model.transform(frames)\n",
    "\n",
    "reconstructed = pca_model.inverse_transform(reduced).reshape(frames.shape)\n",
    "reconstruction_error(frames, np.clip(reconstructed,0,255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "show_video(video.get_all_frames())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Random video loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "v = read_video('data/sample20s.mp4', nframes=24*3)\n",
    "vr = read_video('data/sample20s.mp4', nframes=24*3, random=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 720, 1280, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[0].shape, vr[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "show_video(v[0])\n",
    "show_video(vr[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### SVD on long video, comparison of reconstruction error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting time: 64.06482172012329\n",
      "Transform: 41.710843086242676\n",
      "8.52525261354381\n"
     ]
    }
   ],
   "source": [
    "frames, meta = read_video('data_generated/sample20s_540.mp4')\n",
    "original_shape = frames.shape\n",
    "pca_svd = custom_pca()\n",
    "t1 = time()\n",
    "pca_svd.fit(frames.reshape(frames.shape[0], -1))\n",
    "t2 = time()\n",
    "print('Fitting time:', t2-t1)\n",
    "new_frames = pca_svd.inverse_transform(pca_svd.transform(frames)).reshape(original_shape)\n",
    "t3 = time()\n",
    "print('Transform:', t3-t2)\n",
    "\n",
    "#write_video('data_generated/sample20s_540_svdpca.mp4', new_frames, meta['width'], meta['height'], meta['fps'])\n",
    "print(reconstruction_error(frames.reshape(new_frames.shape), new_frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting time: 36.644392251968384\n",
      "Transform: 15.273186206817627\n",
      "41.60200538114069\n"
     ]
    }
   ],
   "source": [
    "total_frames = original_shape[0]\n",
    "nframes = int(total_frames*0.5)\n",
    "sample_frames, meta = read_video('data_generated/sample20s_540.mp4', nframes=nframes, random=True)\n",
    "pca_svd = custom_pca()\n",
    "t1 = time()\n",
    "pca_svd.fit(sample_frames.reshape(nframes, -1))\n",
    "t2 = time()\n",
    "print('Fitting time:', t2-t1)\n",
    "\n",
    "new_frames = np.zeros(original_shape)\n",
    "for i, batch_frames in enumerate(VideoLoader('data_generated/sample20s_540.mp4')):\n",
    "    new_batch = pca_svd.inverse_transform(pca_svd.transform(batch_frames))\n",
    "    new_frames[i*64:(i+1)*64] = new_batch.reshape(batch_frames.shape)\n",
    "t3 = time()\n",
    "print('Transform:', t3-t2)\n",
    "\n",
    "#write_video('data_generated/sample20s_540_0.5.mp4', new_frames, meta['width'], meta['height'], meta['fps'])\n",
    "print(reconstruction_error(frames.reshape(new_frames.shape), new_frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting time: 12.123085021972656\n",
      "Transform: 15.299276351928711\n",
      "48.23870056503986\n"
     ]
    }
   ],
   "source": [
    "total_frames = original_shape[0]\n",
    "nframes = int(total_frames*0.25)\n",
    "sample_frames, meta = read_video('data_generated/sample20s_540.mp4', nframes=nframes, random=True)\n",
    "pca_svd = custom_pca()\n",
    "t1 = time()\n",
    "pca_svd.fit(sample_frames.reshape(nframes, -1))\n",
    "t2 = time()\n",
    "print('Fitting time:', t2-t1)\n",
    "\n",
    "new_frames = np.zeros(original_shape)\n",
    "for i, batch_frames in enumerate(VideoLoader('data_generated/sample20s_540.mp4')):\n",
    "    new_batch = pca_svd.inverse_transform(pca_svd.transform(batch_frames))\n",
    "    new_frames[i*64:(i+1)*64] = new_batch.reshape(batch_frames.shape)\n",
    "t3 = time()\n",
    "print('Transform:', t3-t2)\n",
    "\n",
    "write_video('data_generated/sample20s_540_0.25.mp4', new_frames, meta['width'], meta['height'], meta['fps'])\n",
    "print(reconstruction_error(frames.reshape(new_frames.shape), new_frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting time: 6.648501873016357\n",
      "Transform: 15.267206192016602\n",
      "49.19006924618484\n"
     ]
    }
   ],
   "source": [
    "total_frames = original_shape[0]\n",
    "nframes = int(total_frames*0.1)\n",
    "sample_frames, meta = read_video('data_generated/sample20s_540.mp4', nframes=nframes, random=True)\n",
    "pca_svd = custom_pca()\n",
    "t1 = time()\n",
    "pca_svd.fit(sample_frames.reshape(nframes, -1))\n",
    "t2 = time()\n",
    "print('Fitting time:', t2-t1)\n",
    "\n",
    "new_frames = np.zeros(original_shape)\n",
    "for i, batch_frames in enumerate(VideoLoader('data_generated/sample20s_540.mp4')):\n",
    "    new_batch = pca_svd.inverse_transform(pca_svd.transform(batch_frames))\n",
    "    new_frames[i*64:(i+1)*64] = new_batch.reshape(batch_frames.shape)\n",
    "t3 = time()\n",
    "print('Transform:', t3-t2)\n",
    "\n",
    "write_video('data_generated/sample20s_540_0.1.mp4', new_frames, meta['width'], meta['height'], meta['fps'])\n",
    "print(reconstruction_error(frames.reshape(new_frames.shape), new_frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting time: 5.889437913894653\n",
      "Transform: 15.425113677978516\n",
      "271.09038918761786\n"
     ]
    }
   ],
   "source": [
    "total_frames = original_shape[0]\n",
    "nframes = int(total_frames*0.05)\n",
    "sample_frames, meta = read_video('data_generated/sample20s_540.mp4', nframes=nframes, random=True)\n",
    "pca_svd = custom_pca()\n",
    "t1 = time()\n",
    "pca_svd.fit(sample_frames.reshape(nframes, -1))\n",
    "t2 = time()\n",
    "print('Fitting time:', t2-t1)\n",
    "\n",
    "new_frames = np.zeros(original_shape)\n",
    "for i, batch_frames in enumerate(VideoLoader('data_generated/sample20s_540.mp4')):\n",
    "    new_batch = pca_svd.inverse_transform(pca_svd.transform(batch_frames))\n",
    "    new_frames[i*64:(i+1)*64] = new_batch.reshape(batch_frames.shape)\n",
    "t3 = time()\n",
    "print('Transform:', t3-t2)\n",
    "\n",
    "write_video('data_generated/sample20s_540_0.05.mp4', new_frames, meta['width'], meta['height'], meta['fps'])\n",
    "print(reconstruction_error(frames.reshape(new_frames.shape), new_frames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Comparison of reconstruction with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting time: 331.5185239315033\n",
      "Transform: 32.415708780288696\n",
      "32.78112737868529\n"
     ]
    }
   ],
   "source": [
    "video = VideoLoader('data_generated/sample20s_540.mp4')\n",
    "\n",
    "incremental_pca = IncrementalPCA(n_components=10)\n",
    "t1 = time()\n",
    "for frames in video:\n",
    "    incremental_pca.partial_fit(frames.reshape(frames.shape[0], -1))\n",
    "t2 = time()\n",
    "reduced_frames = incremental_pca.transform(video.get_all_frames().reshape(video.total_frames, -1))\n",
    "new_frames = incremental_pca.inverse_transform(reduced_frames).reshape(video.total_frames, video.height, video.width, 3)\n",
    "t3 = time()\n",
    "\n",
    "print('Fitting time:', t2-t1)\n",
    "print('Transform:', t3-t2)\n",
    "\n",
    "print(reconstruction_error(video.get_all_frames(), new_frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting time: 382.18158316612244\n",
      "Transform: 38.59532570838928\n",
      "32.781283160921156\n"
     ]
    }
   ],
   "source": [
    "video = VideoLoader('data_generated/sample20s_540.mp4', batch_size=96)\n",
    "\n",
    "incremental_pca = IncrementalPCA(n_components=10)\n",
    "t1 = time()\n",
    "for frames in video:\n",
    "    incremental_pca.partial_fit(frames.reshape(frames.shape[0], -1))\n",
    "t2 = time()\n",
    "reduced_frames = incremental_pca.transform(video.get_all_frames().reshape(video.total_frames, -1))\n",
    "new_frames = incremental_pca.inverse_transform(reduced_frames).reshape(video.total_frames, video.height, video.width, 3)\n",
    "t3 = time()\n",
    "\n",
    "print('Fitting time:', t2-t1)\n",
    "print('Transform:', t3-t2)\n",
    "\n",
    "print(reconstruction_error(video.get_all_frames(), new_frames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Big sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "608.3557539173149\n",
      "Fitting time: 46.197591066360474\n",
      "Transform: 87.10507035255432\n",
      "Error calculation: 88.43285274505615\n"
     ]
    }
   ],
   "source": [
    "model = custom_pca()\n",
    "\n",
    "video = VideoLoader('data/big_sample.mp4', grayscale=True, scale=(256, 256))\n",
    "t1 = time()\n",
    "frames_rand = video.get_random_frames(0.2)\n",
    "model.fit(frames_rand)\n",
    "t2 = time()\n",
    "full_shape = (video.total_frames, video.height, video.width)\n",
    "reconstructed = np.zeros(full_shape)\n",
    "for j, frames in enumerate(video):\n",
    "    nbatch = frames.shape[0]\n",
    "    reconstructed[j*nbatch:(j+1)*nbatch] = model.inverse_transform(model.transform(frames)).reshape(nbatch, video.width, video.height)\n",
    "t3 = time()\n",
    "print(reconstruction_error(video.get_all_frames(), reconstructed))\n",
    "t4 = time()\n",
    "\n",
    "print('Fitting time:', t2-t1)\n",
    "print('Transform:', t3-t2)\n",
    "print('Error calculation:', t4-t3)\n",
    "\n",
    "write_video('data/big_sample_reconstructed.mp4', reconstructed, video.width, video.height, video.fps, grayscale=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
