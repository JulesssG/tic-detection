{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from time import time, sleep\n",
    "\n",
    "from utils import *\n",
    "from custom_pca import custom_pca\n",
    "from video_loader import VideoLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Example of video transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "model = custom_pca()\n",
    "\n",
    "video = VideoLoader('data/sample20s.mp4', grayscale=True)\n",
    "t1 = time()\n",
    "frames_rand = video.get_random_frames(0.6)\n",
    "model.fit(frames_rand)\n",
    "t2 = time()\n",
    "reconstructed = []\n",
    "for j, frames in enumerate(video):\n",
    "    reconstructed.append(model.inverse_transform(model.transform(frames), shape=(video.height, video.width)))\n",
    "reconstructed = np.vstack(reconstructed)\n",
    "t3 = time()\n",
    "print(reconstruction_error(video.get_all_frames(), reconstructed))\n",
    "t4 = time()\n",
    "\n",
    "print('Fitting time:', t2-t1)\n",
    "print('Transform:', t3-t2)\n",
    "print('Error calculation:', t4-t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### LDS framework\n",
    "\n",
    "Default of linear dynamic system is an ARMA:\n",
    "$$x_{t+1} = Ax_t + Bv_t $$\n",
    "$$y_t = \\phi(x_t) + w_t$$\n",
    "\n",
    "We will begin with:\n",
    "$$x_{t+1} = Ax_t + B $$\n",
    "$$y_t = \\phi(x_t)$$\n",
    "The $y$'s are the frames, $x$ the low dimensional representation (obtained with pca), $\\phi$ the inverse transform of pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "ncomp = 20\n",
    "bs = 64\n",
    "num_epoch = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "model = custom_pca(ncomp=ncomp)\n",
    "\n",
    "video = VideoLoader('data/sample20s.mp4', grayscale=True)\n",
    "frames_rand = video.get_random_frames(0.5)\n",
    "model.fit(frames_rand)\n",
    "\n",
    "reduced = []\n",
    "for frames in video:\n",
    "    reduced.append(model.transform(frames))\n",
    "xs = np.vstack(reduced)\n",
    "\n",
    "reconstructed = []\n",
    "for frame in xs:\n",
    "    reconstructed.append(model.inverse_transform(frame[np.newaxis,:], \n",
    "                                                 shape=(video.height, video.width)))\n",
    "reconstructed = np.vstack(reconstructed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def criterion(output, gt):\n",
    "    return torch.sqrt(torch.mean((output[:-1] - gt[1:])**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244.19300842285156\n",
      "65.34095764160156\n",
      "51.71570587158203\n",
      "44.89241409301758\n",
      "40.84038543701172\n",
      "38.30612564086914\n",
      "36.67134094238281\n",
      "35.57298278808594\n",
      "34.81026077270508\n",
      "34.250606536865234\n",
      "33.81930160522461\n",
      "33.47224807739258\n",
      "33.18277359008789\n",
      "32.93437194824219\n",
      "32.71657943725586\n",
      "32.52256393432617\n",
      "32.34769821166992\n",
      "32.18877410888672\n",
      "32.04341506958008\n",
      "31.90989875793457\n"
     ]
    }
   ],
   "source": [
    "#xs = torch.from_numpy(xs)\n",
    "lds = nn.Linear(ncomp, ncomp)\n",
    "optimizer = torch.optim.SGD(lds.parameters(), 0.0001)\n",
    "for i in range(num_epoch):\n",
    "    for batch in xs.split(bs):\n",
    "        output = lds(batch)\n",
    "        loss = criterion(output, batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        with torch.no_grad():\n",
    "            print(criterion(lds(xs), xs).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "xt = xs[0]\n",
    "generated = [xt.numpy()]\n",
    "for i in range(len(xs)-1):\n",
    "    xt = lds(xt)\n",
    "    generated.append(xt.detach().numpy())\n",
    "\n",
    "ys = []\n",
    "for xt in generated:\n",
    "    ys.append(model.inverse_transform(xt).reshape(video.height, video.width))\n",
    "ys = np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "show_video(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error of reconstruction:\n",
      "Without prediction: 2.3006290616128737\n",
      "With prediction: 8.962386536253646\n"
     ]
    }
   ],
   "source": [
    "print(\"Error of reconstruction:\")\n",
    "print(\"Without prediction:\", reconstruction_error(video.get_all_frames(), reconstructed))\n",
    "print(\"With prediction:\", reconstruction_error(video.get_all_frames(), ys))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Error comparison for big sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for 10 components: 8.61885756190244\n",
      "Time (sec): 13 42 14\n",
      "Error for 25 components: 8.111123779458891\n",
      "Time (sec): 14 39 13\n",
      "Error for 50 components: 7.601662169072708\n",
      "Time (sec): 16 44 12\n",
      "Error for 100 components: 6.8247443219756105\n",
      "Time (sec): 26 51 12\n",
      "Error for 150 components: 6.305454986780473\n",
      "Time (sec): 34 55 19\n"
     ]
    }
   ],
   "source": [
    "video = VideoLoader('data/big_sample_256.mp4', grayscale=True)\n",
    "\n",
    "for ncomp in [10,25,50,100,150]:\n",
    "    t1 = time()\n",
    "    pca_model = custom_pca(ncomp)\n",
    "    pca_model.fit(video.get_random_frames(0.2))\n",
    "    \n",
    "    t2 = time()\n",
    "    reconstructed = []\n",
    "    for frames in video:\n",
    "        reconstructed.append(pca_model.inverse_transform(pca_model.transform(frames), \n",
    "                                                         shape=(video.height, video.width)))\n",
    "    reconstructed = np.vstack(reconstructed)\n",
    "    write_video(f'data/big_sample_{ncomp}.mp4', reconstructed, video.width, video.height, video.fps, grayscale=True)\n",
    "    t3 = time()\n",
    "    print(f\"Error for {ncomp} components:\", reconstruction_error(video.get_all_frames(), reconstructed))\n",
    "    t4 = time()\n",
    "    print(f\"Time (sec):\", int(t2-t1), int(t3-t2), int(t4-t3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
