{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Copy of testing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNmt8XXf3WaM"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import datetime\n",
        "from matplotlib import pyplot as plt\n",
        "    \n",
        "def write_video(filename, frames, width, height, fps, grayscale=False):\n",
        "    if grayscale:\n",
        "        writer = cv2.VideoWriter(filename, cv2.VideoWriter_fourcc(*\"MP4V\"), fps, (width, height), 0)\n",
        "    else:\n",
        "        writer = cv2.VideoWriter(filename, cv2.VideoWriter_fourcc(*\"MP4V\"), fps, (width, height))\n",
        "    \n",
        "    for frame in np.clip(np.around(frames), 0, 255).astype(np.uint8):\n",
        "        writer.write(frame)\n",
        "    writer.release()\n",
        "\n",
        "def show_video(frames, imduration=int(1000/24.0)):\n",
        "    for frame in frames:\n",
        "        cv2.imshow('frame',frame)\n",
        "        if cv2.waitKey(imduration) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "def reconstruction_error(frames1, frames2):\n",
        "    if frames1.shape != frames2.shape:\n",
        "        return -1\n",
        "    return np.sqrt(np.mean((frames1 - frames2)**2))\n",
        "\n",
        "def crit(output, gt):\n",
        "    return torch.sqrt(torch.mean((output - gt)**2))\n",
        "\n",
        "def normalize_frames(frames, **kwargs):\n",
        "    mean = kwargs['mean'] if 'mean' in kwargs else np.mean(frames)\n",
        "    frames = frames - mean\n",
        "    std  = kwargs['std'] if 'std' in kwargs else np.std(frames)\n",
        "    frames = frames / std\n",
        "    \n",
        "    return frames\n",
        "\n",
        "styles = ['C'+str(c)+'-'+s for s in ['', '.', 'o', '^'] for c in [0, 1, 2, 3, 6, 8, 9] ]\n",
        "def plot(x, ys, **kwargs):\n",
        "    if len(ys) > len(styles):\n",
        "        print('Duplicate styles')\n",
        "    \n",
        "    if 'fontsize' in kwargs:\n",
        "        plt.rcParams.update({'font.size': kwargs['fontsize']})\n",
        "    else:\n",
        "        plt.rcParams.update({'font.size': 12})\n",
        "        \n",
        "        \n",
        "    if 'figsize' in kwargs:\n",
        "        plt.figure(figsize=kwargs['figsize'])\n",
        "    else:\n",
        "        plt.figure(figsize=(15,10))\n",
        "        \n",
        "    if 'xlabel' in kwargs:\n",
        "        plt.xlabel(kwargs['xlabel'])\n",
        "    if 'ylabel' in kwargs:\n",
        "        plt.ylabel(kwargs['ylabel'])\n",
        "        \n",
        "    if 'yrange' in kwargs:\n",
        "        low, high = kwargs['yrange']\n",
        "        plt.ylim(low, high)\n",
        "    \n",
        "    if 'bound_to_plot' in kwargs:\n",
        "        epoch, max_error = kwargs['bound_to_plot']\n",
        "        ys = list(filter(lambda x: max(x[epoch:]) < max_error, ys))\n",
        "        \n",
        "        \n",
        "    if 'labels' in kwargs:\n",
        "        for i, (y, label) in enumerate(zip(ys, kwargs['labels'])):\n",
        "            plt.plot(x, y, styles[i], label=label)\n",
        "        plt.legend()\n",
        "    else:\n",
        "        for y in ys:\n",
        "            plt.plot(x, y)\n",
        "\n",
        "    if 'title' in kwargs:\n",
        "        plt.title(kwargs['title'])\n",
        "\n",
        "\n",
        "def sec2string(sec):\n",
        "    if sec <= 60:\n",
        "        return round(sec, 2)\n",
        "    secr = round(sec)\n",
        "    \n",
        "    return str(datetime.timedelta(seconds=secr)).strip(\"00:\")\n",
        "import numpy as np # for prod\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class PCAAutoEncoder(nn.Module):\n",
        "    def __init__(self, shape, ncomp):\n",
        "        super().__init__()\n",
        "        infeatures = np.prod(shape)\n",
        "        self.shape = shape\n",
        "        self.to_lower_rep = nn.Linear(infeatures, ncomp)\n",
        "        self.from_lower_rep = nn.Linear(ncomp, infeatures)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.from_lower_rep(self.to_lower_rep(x))\n",
        "        \n",
        "        return x.view(x.shape[0], *self.shape)\n",
        "\n",
        "class OneHAutoEncoder(nn.Module):\n",
        "    def __init__(self, shape, ncomp, nl=nn.ReLU):\n",
        "        super().__init__()\n",
        "        infeatures = np.prod(shape)\n",
        "        self.shape = shape\n",
        "        self.ncomp = ncomp\n",
        "        self.hidden_dim = 200\n",
        "        self.to_lower_rep = nn.Sequential(nn.Linear(infeatures, self.hidden_dim),\n",
        "                                          nl(), \n",
        "                                          nn.Linear(self.hidden_dim, ncomp))\n",
        "        self.from_lower_rep = nn.Sequential(nn.Linear(ncomp, self.hidden_dim),\n",
        "                                           nl(),\n",
        "                                           nn.Linear(self.hidden_dim, infeatures))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.from_lower_rep(self.to_lower_rep(x))\n",
        "        \n",
        "        return x.view(x.shape[0], *self.shape)\n",
        "    \n",
        "class SpatialConvAE(nn.Module):\n",
        "    def __init__(self, inchannels, ncomp, nl=nn.ReLU, chans=[128, 128, 64]):\n",
        "        super().__init__()\n",
        "        self.ncomp = ncomp\n",
        "        self.chans = chans\n",
        "        \n",
        "        self.encoder_convs = nn.Sequential(nn.Conv2d(inchannels, chans[0], kernel_size=26, stride=5), nl(), # 47\n",
        "                                           nn.Conv2d(chans[0], chans[1], kernel_size=11, stride=3), nl(), # 13\n",
        "                                           nn.Conv2d(chans[1], chans[2], kernel_size=6), nl()) # 8\n",
        "        \n",
        "        self.encoder_lin = nn.Linear(chans[2]*8*8, ncomp)\n",
        "        self.decoder_lin = nn.Linear(ncomp, chans[2]*8*8)\n",
        "        \n",
        "        self.decoder_convs = nn.Sequential(nn.ConvTranspose2d(chans[2], chans[1], kernel_size=6), nl(),\n",
        "                                           nn.ConvTranspose2d(chans[1], chans[0], kernel_size=11, stride=3), nl(),\n",
        "                                           nn.ConvTranspose2d(chans[0], inchannels, kernel_size=26, stride=5))\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.encoder_convs(x)\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.encoder_lin(x)\n",
        "        x = self.decoder_lin(x)\n",
        "        x = x.view(x.shape[0], self.chans[2], 8, 8)\n",
        "        x = self.decoder_convs(x)\n",
        "        \n",
        "        return x\n",
        "    \n",
        "class TemporalConvAE(nn.Module):\n",
        "    def __init__(self, inchannels, nlayers, layerchans):\n",
        "        super().__init__()\n",
        "        self.inchannels = inchannels\n",
        "        self.layerchans = layerchans\n",
        "        c1 = c2 = c3 = c4 = c5 = layerchans\n",
        "        \n",
        "        conv_params = [(inchannels, c1, 8, 2), # (1, c1, 29, 125, 125)\n",
        "                       (c1, c2, 7, (1, 2, 2)), # (1, c2, 23, 60, 60)\n",
        "                       (c2, c3, 8, (1, 2, 2)), # (1, c3, 16, 27, 27)\n",
        "                       (c3, c4, 7, (1, 2, 2)), # (1, c4, 10, 11, 11)\n",
        "                       (c4, c5, 5, (1, 2, 2))] # (1, c5, 6, 4, 4)\n",
        "        \n",
        "        encoder_modules = []\n",
        "        for params in conv_params[:nlayers]:\n",
        "            encoder_modules.append(nn.Conv3d(params[0], params[1], kernel_size=params[2], stride=params[3]))\n",
        "            encoder_modules.append(nn.ReLU())\n",
        "        self.encoder_convs = nn.Sequential(*encoder_modules)\n",
        "        \n",
        "        decoder_modules = []\n",
        "        for params in conv_params[:nlayers][::-1]:\n",
        "            decoder_modules.append(nn.ConvTranspose3d(params[1], params[0], kernel_size=params[2], stride=params[3]))\n",
        "            decoder_modules.append(nn.ReLU())\n",
        "        self.decoder_convs = nn.Sequential(*decoder_modules)\n",
        "        \n",
        "        \"\"\"\n",
        "        self.encoder_convs = nn.Sequential(nn.Conv3d(inchannels, c1, kernel_size=8, stride=2), nn.ReLU(), # 125\n",
        "                                          nn.Conv3d(c1, c2, kernel_size=7, stride=2), nn.ReLU(), nn.ReLU(), # 60\n",
        "                                          nn.Conv3d(c2, c3, kernel_size=8, stride=2), nn.ReLU(), # 27\n",
        "                                          nn.Conv3d(c3, c4, kernel_size=7, stride=2), nn.ReLU(),  # 11\n",
        "                                          nn.Conv3d(c4, c5, kernel_size=5, stride=2), nn.ReLU())  # 4\n",
        "                                          \n",
        "        \"\"\"\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.encoder_convs(x)\n",
        "        x = self.decoder_convs(x)\n",
        "        \n",
        "        return x\n",
        "        \n",
        "import numpy as np\n",
        "import torch\n",
        "import cv2\n",
        "\n",
        "class VideoLoader:\n",
        "    def __init__(self, filename, duration=np.inf, batch_size=64, gray=False, scale=None, skip_frame=0, randit=False, torch=True):\n",
        "        self.filename = filename\n",
        "        self.gray = gray\n",
        "        self.batch_size = batch_size\n",
        "        cap = cv2.VideoCapture(filename)\n",
        "        self.total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        self.fps = round(cap.get(cv2.CAP_PROP_FPS))\n",
        "        self.duration_frames = min(self.total_frames, np.ceil(duration*self.fps/batch_size)*batch_size)\n",
        "        self.duration = self.duration_frames/self.fps\n",
        "        self.width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        self.height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        if scale:\n",
        "            self.scale = True\n",
        "            self.original_width  = self.width\n",
        "            self.original_height = self.height\n",
        "            self.width, self.height = scale\n",
        "        else:\n",
        "            self.scale = False\n",
        "        self.skip_frame = skip_frame\n",
        "        self.randit = randit\n",
        "        self.torch = torch\n",
        "        \n",
        "    def reduce_latent(self, model, trans=True):\n",
        "        self.randit = self.skip_frame = 0\n",
        "        \n",
        "        reconstructed_frames = []\n",
        "        for frames in self:\n",
        "            # WILL ALWAYS BE TRANSFORM -> INV_TRANSFORM\n",
        "            if trans:\n",
        "                if self.torch:\n",
        "                    reconstructed_frames.append(model.inverse_transform(*model.transform(frames)).detach())\n",
        "                else:\n",
        "                    reconstructed_frames.append(model.inverse_transform(*model.transform(frames)))\n",
        "            else:\n",
        "                reconstructed_frames.append(model(frames).detach())\n",
        "\n",
        "        if self.torch:\n",
        "            reconstructed_frames = torch.cat(reconstructed_frames, 0)\n",
        "        else:\n",
        "            reconstructed_frames = np.vstack(reconstructed_frames)\n",
        "        return reconstructed_frames\n",
        "        \n",
        "    def get_all_frames(self):\n",
        "        frames = []\n",
        "        cap = cv2.VideoCapture(self.filename)\n",
        "        current_frame = 0\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if current_frame >= self.duration_frames:\n",
        "                cap.release()\n",
        "                break\n",
        "            if ret:\n",
        "                frames.append(self.frame_transform(frame))\n",
        "                current_frame += 1\n",
        "            else:\n",
        "                cap.release()\n",
        "        \n",
        "        return self.__from_frame_list(frames)\n",
        "    \n",
        "    def get_random_frames(self, frames_ratio, seed=42):\n",
        "        nframes = int(self.duration_frames * frames_ratio)\n",
        "        frames = []\n",
        "        cap = cv2.VideoCapture(self.filename)\n",
        "        np.random.seed(seed)\n",
        "        frame_ids = np.random.choice(np.arange(self.duration_frames), \n",
        "                                     size=nframes, \n",
        "                                     replace=False, )\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            current_frame = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
        "            if ret:\n",
        "                if current_frame in frame_ids:\n",
        "                    frames.append(self.frame_transform(frame))\n",
        "            else:\n",
        "                cap.release()\n",
        "        \n",
        "        return self.__from_frame_list(frames)\n",
        "            \n",
        "\n",
        "    def frame_transform(self, frame):\n",
        "        if self.scale:\n",
        "            frame = cv2.resize(frame, (self.width, self.height), interpolation=cv2.INTER_AREA)\n",
        "        if self.gray:\n",
        "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "            \n",
        "        return frame\n",
        "    \n",
        "    def __from_frame_list(self, frames):\n",
        "        if self.torch:\n",
        "            frames = torch.FloatTensor(frames)\n",
        "            if self.gray:\n",
        "                frames = frames.unsqueeze(1)\n",
        "            else:\n",
        "                frames = frames.permute((0, 3, 1, 2))\n",
        "        else:\n",
        "            frames = np.array(frames)\n",
        "            if not self.gray:\n",
        "                frames = np.transpose(frames, axes=(0,3, 1, 2))\n",
        "        \n",
        "        return frames\n",
        "    \n",
        "    def __iter__(self):\n",
        "        self.__cap = cv2.VideoCapture(self.filename)\n",
        "        self.__frame_count = 0\n",
        "        self.__frame_order = np.arange(1, self.duration_frames+1)\n",
        "        if self.randit:\n",
        "            np.random.shuffle(self.__frame_order)\n",
        "        self.__frame_order = iter(self.__frame_order)\n",
        "        self.__stop = False\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        if self.__stop:\n",
        "            raise StopIteration()\n",
        "        \n",
        "        frames = []\n",
        "        while self.__cap.isOpened():\n",
        "            try:\n",
        "                next_frame = next(self.__frame_order)\n",
        "                self.__cap.set(cv2.CAP_PROP_POS_FRAMES, next_frame - 1)\n",
        "                for _ in range(self.skip_frame):\n",
        "                    next(self.__frame_order)\n",
        "            except StopIteration:\n",
        "                self.__stop = True\n",
        "                break\n",
        "            ret, frame = self.__cap.read()\n",
        "                \n",
        "            if ret:\n",
        "                frames.append(self.frame_transform(frame))\n",
        "                self.__frame_count += 1\n",
        "            else:\n",
        "                self.__cap.release()\n",
        "                self.__stop = True\n",
        "                break\n",
        "            \n",
        "            if self.__frame_count % self.batch_size == 0:\n",
        "                break\n",
        "\n",
        "        if self.__frame_count*(self.skip_frame+1) >= self.duration_frames:\n",
        "            self.__stop = True\n",
        "            \n",
        "        return self.__from_frame_list(frames)\n",
        "    \n",
        "    def write(self, filename):\n",
        "        last_torch = self.torch\n",
        "        self.torch = False\n",
        "        \n",
        "        if self.gray:\n",
        "            writer = cv2.VideoWriter(filename, cv2.VideoWriter_fourcc(*\"MP4V\"), self.fps, (self.width, self.height), 0)\n",
        "        else:\n",
        "            writer = cv2.VideoWriter(filename, cv2.VideoWriter_fourcc(*\"MP4V\"), self.fps, (self.width, self.height))\n",
        "    \n",
        "        cap = cv2.VideoCapture(self.filename)\n",
        "        current_frame = 0\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if current_frame >= self.duration_frames:\n",
        "                cap.release()\n",
        "                break\n",
        "            if ret:\n",
        "                #print(frame.shape)\n",
        "                frame = self.frame_transform(frame)\n",
        "                #print(frame.shape)\n",
        "                writer.write(frame)\n",
        "                current_frame += 1\n",
        "            else:\n",
        "                cap.release()\n",
        "        \n",
        "        writer.release()\n",
        "        self.torch = last_torch\n",
        "        \n",
        "import numpy as np\n",
        "from sklearn.utils.extmath import randomized_svd\n",
        "\n",
        "class custom_pca():\n",
        "    def __init__(self, ncomp=10):\n",
        "        self.ncomp = ncomp\n",
        "        \n",
        "    def fit(self, frames):\n",
        "        self.mean = np.mean(frames)\n",
        "        self.std = np.std(frames)\n",
        "        frames = (frames - self.mean) / self.std\n",
        "        frames = frames.reshape(frames.shape[0], -1)\n",
        "        self.pc, _, _ = randomized_svd(frames.T, self.ncomp)\n",
        "        \n",
        "    def transform(self, frames):\n",
        "        shape = frames.shape[1:]\n",
        "        if len(shape) > 1:\n",
        "            frames = frames.reshape(frames.shape[0], -1)\n",
        "        frames = (frames - self.mean) / self.std\n",
        "        frames_reduced = self.pc.T @ frames.T\n",
        "        \n",
        "        return frames_reduced.T, shape\n",
        "        \n",
        "    def inverse_transform(self, frames, shape=None, cast=True):\n",
        "        nframes = frames.shape[0]\n",
        "        frames_reconstructed = (self.pc @ frames.T).T\n",
        "        frames_reconstructed = (frames_reconstructed * self.std) + self.mean\n",
        "        \n",
        "        if cast:\n",
        "            frames_reconstructed = np.clip(frames_reconstructed, 0, 255).astype(np.uint8)\n",
        "        if shape:\n",
        "            frames_reconstructed = frames_reconstructed.reshape(nframes, *shape)\n",
        "        \n",
        "        return frames_reconstructed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "FHDHLOsL2uCY"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import torch\n",
        "import torch.functional as F\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from time import time, sleep\n",
        "\n",
        "\n",
        "seed = 42"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "xDwCmhX02uCo"
      },
      "source": [
        "### Temporal Convolutional AE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "scrolled": true,
        "id": "GCMQbYNI2uCx",
        "outputId": "cb5c93f3-26cc-47b1-86f5-82cb8cef819f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "video = VideoLoader('R25_gray_scaled.mp4', duration=10, gray=True, randit=True)\n",
        "num_epoch, num_epoch_tune = 30, 10\n",
        "iteration_per_epoch = int(video.duration_frames/video.batch_size)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device', device)\n",
        "if device.type == 'cuda':\n",
        "  print(torch.cuda.get_device_name(0))\n",
        "\n",
        "all_losses = {}\n",
        "lrs = {1: [5e-4, 0.001, 0.005],\n",
        "       2: [5e-4, 0.001],\n",
        "       3: [5e-4, 0.001],\n",
        "       4: [5e-5, 1e-4, 5e-4],\n",
        "       5: [1e-5, 5e-5, 1e-4, 5e-4]}\n",
        "for nlayers in range(1, 6):\n",
        "  for layerchans in [4, 8, 12]:\n",
        "    total_time_start = time()\n",
        "    print(f'Model with {nlayers} layer with {layerchans} channels:')\n",
        "\n",
        "    losses_tune = []\n",
        "    for lr in lrs[nlayers]:\n",
        "      torch.manual_seed(seed)\n",
        "      np.random.seed(seed)\n",
        "      model = TemporalConvAE(1, nlayers, layerchans).to(device)\n",
        "      optimizer = Adam(model.parameters(), lr=lr)\n",
        "      for epoch in range(num_epoch_tune):\n",
        "        epoch_loss = 0\n",
        "        for frames in video:\n",
        "          frames = frames.view(-1, 1, video.batch_size, video.height, video.width).to(device)\n",
        "          reconstructed = model(frames)\n",
        "          loss = crit(frames, reconstructed)\n",
        "          \n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          epoch_loss += loss.item()\n",
        "      losses_tune.append(epoch_loss / iteration_per_epoch)\n",
        "    lr = lrs[nlayers][np.argmin(losses_tune)]\n",
        "    print('Chosen learning rate:', lr)\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    model = TemporalConvAE(1, nlayers, layerchans).to(device)\n",
        "    optimizer = Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    t1 = time()\n",
        "    losses = []\n",
        "    for epoch in range(num_epoch):\n",
        "      epoch_loss = 0\n",
        "      for frames in video:\n",
        "        frames = frames.view(-1, 1, video.batch_size, video.height, video.width).to(device)\n",
        "        reconstructed = model(frames)\n",
        "        loss = crit(frames, reconstructed)\n",
        "                \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "      losses.append(epoch_loss / iteration_per_epoch)\n",
        "      if (epoch+1) % 3 == 0:\n",
        "        print(f'\\t Error at epoch {epoch+1}:', losses[-1])\n",
        "    all_losses[f'{nlayers},{layerchans}'] = ((time()-t1)/num_epoch, losses)\n",
        "    print('Total time for model:', sec2string(time()-total_time_start))\n",
        "\n",
        "print(all_losses)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using device cuda\n",
            "Tesla K80\n",
            "Model with 1 layer with 4 channels:\n",
            "Chosen learning rate: 0.001\n",
            "\t Error at epoch 3: 57.36143493652344\n",
            "\t Error at epoch 6: 49.19762191772461\n",
            "\t Error at epoch 9: 46.23065719604492\n",
            "\t Error at epoch 12: 45.10911560058594\n",
            "\t Error at epoch 15: 44.23296890258789\n",
            "\t Error at epoch 18: 43.47725601196289\n",
            "\t Error at epoch 21: 42.667728424072266\n",
            "\t Error at epoch 24: 42.34994049072266\n",
            "\t Error at epoch 27: 42.08884201049805\n",
            "\t Error at epoch 30: 41.75653839111328\n",
            "Total time for model: 6:35\n",
            "Model with 1 layer with 8 channels:\n",
            "Chosen learning rate: 0.001\n",
            "\t Error at epoch 3: 52.99357299804687\n",
            "\t Error at epoch 6: 46.6766357421875\n",
            "\t Error at epoch 9: 45.21807174682617\n",
            "\t Error at epoch 12: 44.29331970214844\n",
            "\t Error at epoch 15: 43.36727523803711\n",
            "\t Error at epoch 18: 42.57135009765625\n",
            "\t Error at epoch 21: 41.781185913085935\n",
            "\t Error at epoch 24: 41.45039672851563\n",
            "\t Error at epoch 27: 41.189398193359374\n",
            "\t Error at epoch 30: 40.91673202514649\n",
            "Total time for model: 6:36\n",
            "Model with 1 layer with 12 channels:\n",
            "Chosen learning rate: 0.001\n",
            "\t Error at epoch 3: 55.321826171875\n",
            "\t Error at epoch 6: 47.99103546142578\n",
            "\t Error at epoch 9: 45.9526252746582\n",
            "\t Error at epoch 12: 44.74865646362305\n",
            "\t Error at epoch 15: 43.67263412475586\n",
            "\t Error at epoch 18: 42.74892120361328\n",
            "\t Error at epoch 21: 41.89269104003906\n",
            "\t Error at epoch 24: 41.50514907836914\n",
            "\t Error at epoch 27: 41.17170944213867\n",
            "\t Error at epoch 30: 40.88034210205078\n",
            "Total time for model: 6:37\n",
            "Model with 2 layer with 4 channels:\n",
            "Chosen learning rate: 0.001\n",
            "\t Error at epoch 3: 81.48786163330078\n",
            "\t Error at epoch 6: 67.74643249511719\n",
            "\t Error at epoch 9: 51.28462219238281\n",
            "\t Error at epoch 12: 42.08822021484375\n",
            "\t Error at epoch 15: 36.6408073425293\n",
            "\t Error at epoch 18: 33.12904739379883\n",
            "\t Error at epoch 21: 31.5284065246582\n",
            "\t Error at epoch 24: 29.71269416809082\n",
            "\t Error at epoch 27: 30.275751876831055\n",
            "\t Error at epoch 30: 27.66942443847656\n",
            "Total time for model: 6:03\n",
            "Model with 2 layer with 8 channels:\n",
            "Chosen learning rate: 0.0005\n",
            "\t Error at epoch 3: 83.99110565185546\n",
            "\t Error at epoch 6: 71.0464599609375\n",
            "\t Error at epoch 9: 55.02199935913086\n",
            "\t Error at epoch 12: 44.85856170654297\n",
            "\t Error at epoch 15: 38.96578598022461\n",
            "\t Error at epoch 18: 34.263414001464845\n",
            "\t Error at epoch 21: 31.665459823608398\n",
            "\t Error at epoch 24: 30.37889518737793\n",
            "\t Error at epoch 27: 28.323711013793947\n",
            "\t Error at epoch 30: 27.00345458984375\n",
            "Total time for model: 6:15\n",
            "Model with 2 layer with 12 channels:\n",
            "Chosen learning rate: 0.001\n",
            "\t Error at epoch 3: 87.4773193359375\n",
            "\t Error at epoch 6: 62.97249221801758\n",
            "\t Error at epoch 9: 44.4063117980957\n",
            "\t Error at epoch 12: 34.11466827392578\n",
            "\t Error at epoch 15: 29.063439178466798\n",
            "\t Error at epoch 18: 26.501491165161134\n",
            "\t Error at epoch 21: 24.85918731689453\n",
            "\t Error at epoch 24: 24.281640243530273\n",
            "\t Error at epoch 27: 22.87337417602539\n",
            "\t Error at epoch 30: 22.698152923583983\n",
            "Total time for model: 6:27\n",
            "Model with 3 layer with 4 channels:\n",
            "Chosen learning rate: 0.0005\n",
            "\t Error at epoch 3: 124.19857788085938\n",
            "\t Error at epoch 6: 104.71405792236328\n",
            "\t Error at epoch 9: 76.65931854248046\n",
            "\t Error at epoch 12: 63.30954513549805\n",
            "\t Error at epoch 15: 53.55891799926758\n",
            "\t Error at epoch 18: 46.58454208374023\n",
            "\t Error at epoch 21: 41.51706161499023\n",
            "\t Error at epoch 24: 38.57195205688477\n",
            "\t Error at epoch 27: 37.28915863037109\n",
            "\t Error at epoch 30: 34.031439208984374\n",
            "Total time for model: 6:09\n",
            "Model with 3 layer with 8 channels:\n",
            "Chosen learning rate: 0.001\n",
            "\t Error at epoch 3: 103.39723358154296\n",
            "\t Error at epoch 6: 63.76657409667969\n",
            "\t Error at epoch 9: 48.062618255615234\n",
            "\t Error at epoch 12: 39.846797943115234\n",
            "\t Error at epoch 15: 46.20554885864258\n",
            "\t Error at epoch 18: 36.494071578979494\n",
            "\t Error at epoch 21: 29.693089294433594\n",
            "\t Error at epoch 24: 29.351213455200195\n",
            "\t Error at epoch 27: 28.741741180419922\n",
            "\t Error at epoch 30: 27.519873428344727\n",
            "Total time for model: 6:25\n",
            "Model with 3 layer with 12 channels:\n",
            "Chosen learning rate: 0.0005\n",
            "\t Error at epoch 3: 155.45571899414062\n",
            "\t Error at epoch 6: 130.71519317626954\n",
            "\t Error at epoch 9: 114.9658706665039\n",
            "\t Error at epoch 12: 80.5055145263672\n",
            "\t Error at epoch 15: 59.90581588745117\n",
            "\t Error at epoch 18: 51.9974479675293\n",
            "\t Error at epoch 21: 41.98749618530273\n",
            "\t Error at epoch 24: 36.61270446777344\n",
            "\t Error at epoch 27: 33.26302261352539\n",
            "\t Error at epoch 30: 30.674560928344725\n",
            "Total time for model: 6:42\n",
            "Model with 4 layer with 4 channels:\n",
            "Chosen learning rate: 5e-05\n",
            "\t Error at epoch 3: 155.7118408203125\n",
            "\t Error at epoch 6: 155.7117492675781\n",
            "\t Error at epoch 9: 155.71188659667968\n",
            "\t Error at epoch 12: 155.71185607910155\n",
            "\t Error at epoch 15: 155.71185302734375\n",
            "\t Error at epoch 18: 155.71186218261718\n",
            "\t Error at epoch 21: 155.7117462158203\n",
            "\t Error at epoch 24: 155.7118347167969\n",
            "\t Error at epoch 27: 155.71188049316407\n",
            "\t Error at epoch 30: 155.71165161132814\n",
            "Total time for model: 7:23\n",
            "Model with 4 layer with 8 channels:\n",
            "Chosen learning rate: 0.0005\n",
            "\t Error at epoch 3: 153.29266967773438\n",
            "\t Error at epoch 6: 126.11480865478515\n",
            "\t Error at epoch 9: 81.94446411132813\n",
            "\t Error at epoch 12: 57.70263900756836\n",
            "\t Error at epoch 15: 45.710533142089844\n",
            "\t Error at epoch 18: 41.81436996459961\n",
            "\t Error at epoch 21: 34.96889038085938\n",
            "\t Error at epoch 24: 31.686660766601562\n",
            "\t Error at epoch 27: 29.808747863769533\n",
            "\t Error at epoch 30: 28.52298355102539\n",
            "Total time for model: 7:43\n",
            "Model with 4 layer with 12 channels:\n",
            "Chosen learning rate: 0.0001\n",
            "\t Error at epoch 3: 137.62862854003907\n",
            "\t Error at epoch 6: 118.04994354248046\n",
            "\t Error at epoch 9: 84.19897918701172\n",
            "\t Error at epoch 12: 64.61834030151367\n",
            "\t Error at epoch 15: 52.11894760131836\n",
            "\t Error at epoch 18: 44.41022644042969\n",
            "\t Error at epoch 21: 39.52220993041992\n",
            "\t Error at epoch 24: 36.1157730102539\n",
            "\t Error at epoch 27: 33.72002029418945\n",
            "\t Error at epoch 30: 31.9369327545166\n",
            "Total time for model: 8:01\n",
            "Model with 5 layer with 4 channels:\n",
            "Chosen learning rate: 0.0005\n",
            "\t Error at epoch 3: 155.62259216308593\n",
            "\t Error at epoch 6: 141.84473876953126\n",
            "\t Error at epoch 9: 130.39500427246094\n",
            "\t Error at epoch 12: 118.40609130859374\n",
            "\t Error at epoch 15: 92.7956771850586\n",
            "\t Error at epoch 18: 67.6155990600586\n",
            "\t Error at epoch 21: 53.04783477783203\n",
            "\t Error at epoch 24: 44.438819885253906\n",
            "\t Error at epoch 27: 39.39053802490234\n",
            "\t Error at epoch 30: 36.74416046142578\n",
            "Total time for model: 8:38\n",
            "Model with 5 layer with 8 channels:\n",
            "Chosen learning rate: 1e-05\n",
            "\t Error at epoch 3: 155.7118408203125\n",
            "\t Error at epoch 6: 155.7117492675781\n",
            "\t Error at epoch 9: 155.71188659667968\n",
            "\t Error at epoch 12: 155.71185607910155\n",
            "\t Error at epoch 15: 155.71185302734375\n",
            "\t Error at epoch 18: 155.71186218261718\n",
            "\t Error at epoch 21: 155.7117462158203\n",
            "\t Error at epoch 24: 155.7118347167969\n",
            "\t Error at epoch 27: 155.71188049316407\n",
            "\t Error at epoch 30: 155.71165161132814\n",
            "Total time for model: 8:59\n",
            "Model with 5 layer with 12 channels:\n",
            "Chosen learning rate: 1e-05\n",
            "\t Error at epoch 3: 155.7118408203125\n",
            "\t Error at epoch 6: 155.7117492675781\n",
            "\t Error at epoch 9: 155.71188659667968\n",
            "\t Error at epoch 12: 155.71185607910155\n",
            "\t Error at epoch 15: 155.71185302734375\n",
            "\t Error at epoch 18: 155.71186218261718\n",
            "\t Error at epoch 21: 155.7117462158203\n",
            "\t Error at epoch 24: 155.7118347167969\n",
            "\t Error at epoch 27: 155.71188049316407\n",
            "\t Error at epoch 30: 155.71165161132814\n",
            "Total time for model: 9:23\n",
            "{'1,4': (6.586507868766785, [119.86585693359375, 71.62616882324218, 57.36143493652344, 52.73775405883789, 50.44563598632813, 49.19762191772461, 47.61673126220703, 46.979776000976564, 46.23065719604492, 45.796818542480466, 45.407466125488284, 45.10911560058594, 44.758898162841795, 44.49137573242187, 44.23296890258789, 43.990708923339845, 43.73202362060547, 43.47725601196289, 43.21266632080078, 43.07197952270508, 42.667728424072266, 42.59295654296875, 42.57632751464844, 42.34994049072266, 42.20378875732422, 42.13644027709961, 42.08884201049805, 41.9168701171875, 41.80000762939453, 41.75653839111328]), '1,8': (6.586618749300639, [99.47498626708985, 56.273155975341794, 52.99357299804687, 48.82014846801758, 48.37613525390625, 46.6766357421875, 46.25408401489258, 45.78227615356445, 45.21807174682617, 44.97126388549805, 44.5754753112793, 44.29331970214844, 43.915373992919925, 43.62699584960937, 43.36727523803711, 43.105847930908205, 42.856040954589844, 42.57135009765625, 42.31905670166016, 42.178252410888675, 41.781185913085935, 41.72509002685547, 41.68821487426758, 41.45039672851563, 41.31651153564453, 41.274026489257814, 41.189398193359374, 41.048316955566406, 40.95073471069336, 40.91673202514649]), '1,12': (6.6066405296325685, [96.69454193115234, 67.21086273193359, 55.321826171875, 50.93243255615234, 49.42475204467773, 47.99103546142578, 47.08029327392578, 46.57842864990234, 45.9526252746582, 45.59420623779297, 45.09258270263672, 44.74865646362305, 44.30098648071289, 43.957567596435545, 43.67263412475586, 43.39143371582031, 43.084502410888675, 42.74892120361328, 42.44907073974609, 42.31100769042969, 41.89269104003906, 41.78580780029297, 41.71298446655273, 41.50514907836914, 41.330450439453124, 41.28514022827149, 41.17170944213867, 41.017365264892575, 40.90785598754883, 40.88034210205078]), '2,4': (7.263132866223653, [130.4121887207031, 86.60436706542968, 81.48786163330078, 78.55552825927734, 74.70735778808594, 67.74643249511719, 59.982015991210936, 55.24274520874023, 51.28462219238281, 48.32299728393555, 45.13934097290039, 42.08822021484375, 39.66076126098633, 38.23774719238281, 36.6408073425293, 35.400027465820315, 34.14043960571289, 33.12904739379883, 33.18102951049805, 32.42071647644043, 31.5284065246582, 30.601782989501952, 29.98912124633789, 29.71269416809082, 28.851667404174805, 28.97270278930664, 30.275751876831055, 28.836914443969725, 28.161193084716796, 27.66942443847656]), '2,8': (7.489059742291769, [133.9245849609375, 94.04569702148437, 83.99110565185546, 80.00409240722657, 75.35693817138672, 71.0464599609375, 63.99400100708008, 58.12680282592773, 55.02199935913086, 50.716636657714844, 47.82683563232422, 44.85856170654297, 42.545735931396486, 41.00926666259765, 38.96578598022461, 37.240362548828124, 35.6555908203125, 34.263414001464845, 33.1329460144043, 32.20292625427246, 31.665459823608398, 30.62712516784668, 30.1257625579834, 30.37889518737793, 29.38918342590332, 28.717582321166994, 28.323711013793947, 27.784320068359374, 27.315732192993163, 27.00345458984375]), '2,12': (7.75023984114329, [139.47216796875, 104.64364318847656, 87.4773193359375, 78.62661285400391, 72.67963409423828, 62.97249221801758, 57.036860656738284, 51.13243103027344, 44.4063117980957, 39.624210357666016, 36.66748809814453, 34.11466827392578, 32.37680015563965, 30.707844543457032, 29.063439178466798, 28.885145568847655, 27.102497100830078, 26.501491165161134, 26.273445892333985, 25.1196647644043, 24.85918731689453, 25.305000686645506, 24.81421661376953, 24.281640243530273, 23.3659309387207, 23.24339485168457, 22.87337417602539, 23.553731536865236, 22.497455215454103, 22.698152923583983]), '3,4': (7.364257049560547, [153.99918212890626, 131.28044586181642, 124.19857788085938, 114.52916870117187, 109.13405914306641, 104.71405792236328, 98.3027130126953, 87.17681121826172, 76.65931854248046, 71.89892578125, 67.37055969238281, 63.30954513549805, 59.816246032714844, 56.61063919067383, 53.55891799926758, 50.6595962524414, 48.12362899780273, 46.58454208374023, 44.50057830810547, 42.97583541870117, 41.51706161499023, 40.381103515625, 39.275264739990234, 38.57195205688477, 37.37944564819336, 37.103956604003905, 37.28915863037109, 35.58485717773438, 34.75546722412109, 34.031439208984374]), '3,8': (7.7018019994099935, [150.12652893066405, 126.47030639648438, 103.39723358154296, 81.1334014892578, 73.34529724121094, 63.76657409667969, 59.318060302734374, 52.94909591674805, 48.062618255615234, 44.53564987182617, 43.04826736450195, 39.846797943115234, 36.59346923828125, 37.8779182434082, 46.20554885864258, 47.47858810424805, 40.72224502563476, 36.494071578979494, 32.79701271057129, 32.33912200927735, 29.693089294433594, 29.326105499267577, 29.12495994567871, 29.351213455200195, 28.870009231567384, 28.103890228271485, 28.741741180419922, 28.18741340637207, 27.1087215423584, 27.519873428344727]), '3,12': (8.043717376391093, [156.93194274902345, 155.08192443847656, 155.45571899414062, 153.40630187988282, 139.48853149414063, 130.71519317626954, 125.46438140869141, 120.39087371826172, 114.9658706665039, 106.93074188232421, 95.61192626953125, 80.5055145263672, 71.0509521484375, 65.28769912719727, 59.90581588745117, 56.11423110961914, 56.858194732666014, 51.9974479675293, 47.32066879272461, 44.8067512512207, 41.98749618530273, 39.846717071533206, 38.16906967163086, 36.61270446777344, 35.362857055664065, 34.354225158691406, 33.26302261352539, 32.30325431823731, 31.29112548828125, 30.674560928344725]), '4,4': (7.368047428131104, [155.71189575195314, 155.71177673339844, 155.7118408203125, 155.71182250976562, 155.71184997558595, 155.7117492675781, 155.71176147460938, 155.71172485351562, 155.71188659667968, 155.7118682861328, 155.71185302734375, 155.71185607910155, 155.71184387207032, 155.7117889404297, 155.71185302734375, 155.7118682861328, 155.7118347167969, 155.71186218261718, 155.71182250976562, 155.7118682861328, 155.7117462158203, 155.71185302734375, 155.71185607910155, 155.7118347167969, 155.711865234375, 155.71183166503906, 155.71188049316407, 155.7118377685547, 155.71187744140624, 155.71165161132814]), '4,8': (7.717350427309672, [153.56365661621095, 154.1423095703125, 153.29266967773438, 140.71847534179688, 133.78236694335936, 126.11480865478515, 112.48727264404297, 97.6794418334961, 81.94446411132813, 73.71990051269532, 65.61777114868164, 57.70263900756836, 52.05810317993164, 47.51001815795898, 45.710533142089844, 43.516990661621094, 46.44974975585937, 41.81436996459961, 38.4075065612793, 36.109858703613284, 34.96889038085938, 33.55489044189453, 32.59480438232422, 31.686660766601562, 31.01128807067871, 30.396615982055664, 29.808747863769533, 29.26061248779297, 28.790975189208986, 28.52298355102539]), '4,12': (8.019268504778545, [155.54690246582032, 147.98190612792968, 137.62862854003907, 131.47884521484374, 125.99033660888672, 118.04994354248046, 106.23755645751953, 92.71295623779297, 84.19897918701172, 75.83853759765626, 69.7684112548828, 64.61834030151367, 59.70847930908203, 55.58781127929687, 52.11894760131836, 49.10173110961914, 46.52519836425781, 44.41022644042969, 42.55962905883789, 40.96608352661133, 39.52220993041992, 38.24093017578125, 37.23357925415039, 36.1157730102539, 35.272509002685545, 34.44342575073242, 33.72002029418945, 33.0062873840332, 32.69955749511719, 31.9369327545166]), '5,4': (7.384210793177287, [155.68142700195312, 155.66300354003906, 155.62259216308593, 151.72329711914062, 143.91561889648438, 141.84473876953126, 137.0182647705078, 133.5084655761719, 130.39500427246094, 127.06658935546875, 123.13980102539062, 118.40609130859374, 111.95237579345704, 103.5204345703125, 92.7956771850586, 82.53040771484375, 74.60688781738281, 67.6155990600586, 61.91869964599609, 57.24631958007812, 53.04783477783203, 49.625300598144534, 46.8630615234375, 44.438819885253906, 42.791045379638675, 41.05034561157227, 39.39053802490234, 38.05894393920899, 36.936038970947266, 36.74416046142578]), '5,8': (7.6647642135620115, [155.71189575195314, 155.71177673339844, 155.7118408203125, 155.71182250976562, 155.71184997558595, 155.7117492675781, 155.71176147460938, 155.71172485351562, 155.71188659667968, 155.7118682861328, 155.71185302734375, 155.71185607910155, 155.71184387207032, 155.7117889404297, 155.71185302734375, 155.7118682861328, 155.7118347167969, 155.71186218261718, 155.71182250976562, 155.7118682861328, 155.7117462158203, 155.71185302734375, 155.71185607910155, 155.7118347167969, 155.711865234375, 155.71183166503906, 155.71188049316407, 155.7118377685547, 155.71187744140624, 155.71165161132814]), '5,12': (8.064798227945964, [155.71189575195314, 155.71177673339844, 155.7118408203125, 155.71182250976562, 155.71184997558595, 155.7117492675781, 155.71176147460938, 155.71172485351562, 155.71188659667968, 155.7118682861328, 155.71185302734375, 155.71185607910155, 155.71184387207032, 155.7117889404297, 155.71185302734375, 155.7118682861328, 155.7118347167969, 155.71186218261718, 155.71182250976562, 155.7118682861328, 155.7117462158203, 155.71185302734375, 155.71185607910155, 155.7118347167969, 155.711865234375, 155.71183166503906, 155.71188049316407, 155.7118377685547, 155.71187744140624, 155.71165161132814])}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07LwH8QCE_P1",
        "outputId": "2d232627-a937-4873-f019-86b31692f5e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "video = VideoLoader('R25_gray_scaled.mp4', duration=10, gray=True, randit=True)\n",
        "num_epoch, num_epoch_tune = 30, 10\n",
        "iteration_per_epoch = int(video.duration_frames/video.batch_size)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device', device)\n",
        "if device.type == 'cuda':\n",
        "  print(torch.cuda.get_device_name(0))\n",
        "\n",
        "all_losses = {}\n",
        "lrs = {1: [1e-4, 5e-4, 0.001],\n",
        "       2: [1e-4, 5e-4, 0.001],\n",
        "       3: [1e-4, 5e-4, 0.001],\n",
        "       4: [1e-5, 5e-5, 1e-4, 5e-4],\n",
        "       5: [1e-5, 5e-5, 1e-4, 5e-4]}\n",
        "for nlayers in range(1, 6):\n",
        "  for layerchans in [32, 64]:\n",
        "    total_time_start = time()\n",
        "    print(f'Model with {nlayers} layer with {layerchans} channels:')\n",
        "\n",
        "    losses_tune = []\n",
        "    for lr in lrs[nlayers]:\n",
        "      torch.manual_seed(seed)\n",
        "      np.random.seed(seed)\n",
        "      model = TemporalConvAE(1, nlayers, layerchans).to(device)\n",
        "      optimizer = Adam(model.parameters(), lr=lr)\n",
        "      for epoch in range(num_epoch_tune):\n",
        "        epoch_loss = 0\n",
        "        for frames in video:\n",
        "          frames = frames.view(-1, 1, video.batch_size, video.height, video.width).to(device)\n",
        "          reconstructed = model(frames)\n",
        "          loss = crit(frames, reconstructed)\n",
        "          \n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          epoch_loss += loss.item()\n",
        "      losses_tune.append(epoch_loss / iteration_per_epoch)\n",
        "    lr = lrs[nlayers][np.argmin(losses_tune)]\n",
        "    print('Chosen learning rate:', lr)\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    model = TemporalConvAE(1, nlayers, layerchans).to(device)\n",
        "    optimizer = Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    t1 = time()\n",
        "    losses = []\n",
        "    for epoch in range(num_epoch):\n",
        "      epoch_loss = 0\n",
        "      for frames in video:\n",
        "        frames = frames.view(-1, 1, video.batch_size, video.height, video.width).to(device)\n",
        "        reconstructed = model(frames)\n",
        "        loss = crit(frames, reconstructed)\n",
        "                \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "      losses.append(epoch_loss / iteration_per_epoch)\n",
        "      if (epoch+1) % 3 == 0:\n",
        "        print(f'\\t Error at epoch {epoch+1}:', losses[-1])\n",
        "    all_losses[f'{nlayers},{layerchans}'] = ((time()-t1)/num_epoch, losses)\n",
        "    print('Total time for model:', sec2string(time()-total_time_start))\n",
        "\n",
        "print(all_losses)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using device cuda\n",
            "Tesla K80\n",
            "Model with 1 layer with 32 channels:\n",
            "Chosen learning rate: 0.001\n",
            "\t Error at epoch 3: 51.05170669555664\n",
            "\t Error at epoch 6: 46.67074813842773\n",
            "\t Error at epoch 9: 44.68516845703125\n",
            "\t Error at epoch 12: 43.73015213012695\n",
            "\t Error at epoch 15: 42.71629638671875\n",
            "\t Error at epoch 18: 42.12033309936523\n",
            "\t Error at epoch 21: 41.48017959594726\n",
            "\t Error at epoch 24: 41.237037658691406\n",
            "\t Error at epoch 27: 41.053828430175784\n",
            "\t Error at epoch 30: 40.80555114746094\n",
            "Total time for model: 6:43\n",
            "Model with 1 layer with 64 channels:\n",
            "Chosen learning rate: 0.0005\n",
            "\t Error at epoch 3: 52.02037124633789\n",
            "\t Error at epoch 6: 46.736235809326175\n",
            "\t Error at epoch 9: 44.19419174194336\n",
            "\t Error at epoch 12: 42.356974029541014\n",
            "\t Error at epoch 15: 41.28425521850586\n",
            "\t Error at epoch 18: 40.733621978759764\n",
            "\t Error at epoch 21: 40.161346435546875\n",
            "\t Error at epoch 24: 39.93864364624024\n",
            "\t Error at epoch 27: 39.90627822875977\n",
            "\t Error at epoch 30: 39.67598648071289\n",
            "Total time for model: 6:55\n",
            "Model with 2 layer with 32 channels:\n",
            "Chosen learning rate: 0.0005\n",
            "\t Error at epoch 3: 91.9915786743164\n",
            "\t Error at epoch 6: 65.85408096313476\n",
            "\t Error at epoch 9: 44.8772575378418\n",
            "\t Error at epoch 12: 33.120751571655276\n",
            "\t Error at epoch 15: 28.759826278686525\n",
            "\t Error at epoch 18: 25.824374389648437\n",
            "\t Error at epoch 21: 24.05251350402832\n",
            "\t Error at epoch 24: 23.070681381225587\n",
            "\t Error at epoch 27: 21.929568099975587\n",
            "\t Error at epoch 30: 22.30654373168945\n",
            "Total time for model: 9:19\n",
            "Model with 2 layer with 64 channels:\n",
            "Chosen learning rate: 0.0001\n",
            "\t Error at epoch 3: 91.0424072265625\n",
            "\t Error at epoch 6: 68.54922332763672\n",
            "\t Error at epoch 9: 49.648624420166016\n",
            "\t Error at epoch 12: 38.37748413085937\n",
            "\t Error at epoch 15: 32.772530746459964\n",
            "\t Error at epoch 18: 27.911982345581055\n",
            "\t Error at epoch 21: 25.54422378540039\n",
            "\t Error at epoch 24: 23.970185852050783\n",
            "\t Error at epoch 27: 22.98143539428711\n",
            "\t Error at epoch 30: 21.99435501098633\n",
            "Total time for model: 16:09\n",
            "Model with 3 layer with 32 channels:\n",
            "Chosen learning rate: 0.0001\n",
            "\t Error at epoch 3: 110.48228759765625\n",
            "\t Error at epoch 6: 72.83882598876953\n",
            "\t Error at epoch 9: 55.63190841674805\n",
            "\t Error at epoch 12: 43.383749389648436\n",
            "\t Error at epoch 15: 35.87745666503906\n",
            "\t Error at epoch 18: 30.889654922485352\n",
            "\t Error at epoch 21: 28.172788619995117\n",
            "\t Error at epoch 24: 26.323174285888673\n",
            "\t Error at epoch 27: 24.819701766967775\n",
            "\t Error at epoch 30: 23.951994705200196\n",
            "Total time for model: 10:14\n",
            "Model with 3 layer with 64 channels:\n",
            "Chosen learning rate: 0.0005\n",
            "\t Error at epoch 3: 148.4690155029297\n",
            "\t Error at epoch 6: 134.259423828125\n",
            "\t Error at epoch 9: 91.73970947265624\n",
            "\t Error at epoch 12: 65.74723052978516\n",
            "\t Error at epoch 15: 53.75423355102539\n",
            "\t Error at epoch 18: 41.4045295715332\n",
            "\t Error at epoch 21: 35.400821685791016\n",
            "\t Error at epoch 24: 31.542400741577147\n",
            "\t Error at epoch 27: 29.650181579589844\n",
            "\t Error at epoch 30: 27.575251388549805\n",
            "Total time for model: 17:55\n",
            "Model with 4 layer with 32 channels:\n",
            "Chosen learning rate: 5e-05\n",
            "\t Error at epoch 3: 137.19786682128907\n",
            "\t Error at epoch 6: 112.95846862792969\n",
            "\t Error at epoch 9: 78.85586853027344\n",
            "\t Error at epoch 12: 61.01434478759766\n",
            "\t Error at epoch 15: 49.484911346435545\n",
            "\t Error at epoch 18: 42.04575042724609\n",
            "\t Error at epoch 21: 37.20573272705078\n",
            "\t Error at epoch 24: 33.391503143310544\n",
            "\t Error at epoch 27: 31.245989990234374\n",
            "\t Error at epoch 30: 29.36984176635742\n",
            "Total time for model: 11:5\n",
            "Model with 4 layer with 64 channels:\n",
            "Chosen learning rate: 0.0005\n",
            "\t Error at epoch 3: 144.31059875488282\n",
            "\t Error at epoch 6: 129.51495819091798\n",
            "\t Error at epoch 9: 58.15738372802734\n",
            "\t Error at epoch 12: 44.049947357177736\n",
            "\t Error at epoch 15: 37.629093170166016\n",
            "\t Error at epoch 18: 31.24305953979492\n",
            "\t Error at epoch 21: 28.37405014038086\n",
            "\t Error at epoch 24: 27.323252868652343\n",
            "\t Error at epoch 27: 27.785328674316407\n",
            "\t Error at epoch 30: 34.3030818939209\n",
            "Total time for model: 21:11\n",
            "Model with 5 layer with 32 channels:\n",
            "Chosen learning rate: 1e-05\n",
            "\t Error at epoch 3: 155.7118408203125\n",
            "\t Error at epoch 6: 155.7117492675781\n",
            "\t Error at epoch 9: 155.71188659667968\n",
            "\t Error at epoch 12: 155.71185607910155\n",
            "\t Error at epoch 15: 155.71185302734375\n",
            "\t Error at epoch 18: 155.71186218261718\n",
            "\t Error at epoch 21: 155.7117462158203\n",
            "\t Error at epoch 24: 155.7118347167969\n",
            "\t Error at epoch 27: 155.71188049316407\n",
            "\t Error at epoch 30: 155.71165161132814\n",
            "Total time for model: 11:53\n",
            "Model with 5 layer with 64 channels:\n",
            "Chosen learning rate: 1e-05\n",
            "\t Error at epoch 3: 155.7118408203125\n",
            "\t Error at epoch 6: 155.7117492675781\n",
            "\t Error at epoch 9: 155.71188659667968\n",
            "\t Error at epoch 12: 155.71185607910155\n",
            "\t Error at epoch 15: 155.71185302734375\n",
            "\t Error at epoch 18: 155.71186218261718\n",
            "\t Error at epoch 21: 155.7117462158203\n",
            "\t Error at epoch 24: 155.7118347167969\n",
            "\t Error at epoch 27: 155.71188049316407\n",
            "\t Error at epoch 30: 155.71165161132814\n",
            "Total time for model: 21:24\n",
            "{'1,32': (6.71182476679484, [92.63471984863281, 58.182090759277344, 51.05170669555664, 49.26017761230469, 47.57956771850586, 46.67074813842773, 45.80816802978516, 45.33303298950195, 44.68516845703125, 44.414163970947264, 44.296163940429686, 43.73015213012695, 43.24689559936523, 42.91751480102539, 42.71629638671875, 42.5161849975586, 42.321920013427736, 42.12033309936523, 41.90849838256836, 41.80671081542969, 41.48017959594726, 41.455073547363284, 41.45417785644531, 41.237037658691406, 41.100476837158205, 41.06671981811523, 41.053828430175784, 40.90081100463867, 40.82514266967773, 40.80555114746094]), '1,64': (6.918313543001811, [88.46867523193359, 58.880174255371095, 52.02037124633789, 49.59053726196289, 47.85999221801758, 46.736235809326175, 45.758802795410155, 45.037732696533205, 44.19419174194336, 43.53841934204102, 42.87966613769531, 42.356974029541014, 41.88265380859375, 41.52345657348633, 41.28425521850586, 41.10011672973633, 41.025953674316405, 40.733621978759764, 40.5163818359375, 40.43647079467773, 40.161346435546875, 40.11470718383789, 40.11552505493164, 39.93864364624024, 39.94019622802735, 39.994902801513675, 39.90627822875977, 39.80110855102539, 39.72598419189453, 39.67598648071289]), '2,32': (9.312953273455301, [140.29572448730468, 110.4760238647461, 91.9915786743164, 83.58323364257812, 75.28921051025391, 65.85408096313476, 55.55426559448242, 49.978180694580075, 44.8772575378418, 39.60411148071289, 35.96235809326172, 33.120751571655276, 31.681095123291016, 30.97255516052246, 28.759826278686525, 27.314556121826172, 26.352624893188477, 25.824374389648437, 25.18336181640625, 24.580429077148438, 24.05251350402832, 23.564766311645506, 23.587179946899415, 23.070681381225587, 22.96668243408203, 23.48114356994629, 21.929568099975587, 22.98313331604004, 22.241170501708986, 22.30654373168945]), '2,64': (16.220271984736126, [124.25721893310546, 100.28298645019531, 91.0424072265625, 80.68925476074219, 74.72737274169921, 68.54922332763672, 60.88099975585938, 54.64442901611328, 49.648624420166016, 45.23415908813477, 41.55873260498047, 38.37748413085937, 35.64743881225586, 33.178591918945315, 32.772530746459964, 30.712491607666017, 29.09301643371582, 27.911982345581055, 27.223513412475587, 26.343770599365236, 25.54422378540039, 25.116579818725587, 24.621702575683592, 23.970185852050783, 23.480767059326173, 23.63583984375, 22.98143539428711, 22.68752670288086, 22.40080871582031, 21.99435501098633]), '3,32': (10.245744442939758, [144.04851989746095, 121.72943420410157, 110.48228759765625, 96.70335540771484, 81.39969482421876, 72.83882598876953, 66.1412124633789, 60.58987731933594, 55.63190841674805, 50.77169418334961, 47.03554916381836, 43.383749389648436, 40.19710464477539, 37.986751556396484, 35.87745666503906, 33.901065063476565, 32.20447196960449, 30.889654922485352, 29.813469314575194, 29.02189483642578, 28.172788619995117, 27.900343704223634, 27.04685821533203, 26.323174285888673, 26.376301956176757, 25.630674362182617, 24.819701766967775, 25.293637466430663, 24.132465744018553, 23.951994705200196]), '3,64': (17.92595005830129, [2930.0629699707033, 150.2129333496094, 148.4690155029297, 144.0926971435547, 140.09917907714845, 134.259423828125, 123.35794677734376, 107.01603393554687, 91.73970947265624, 81.00618286132813, 71.25652923583985, 65.74723052978516, 60.86029968261719, 58.83183212280274, 53.75423355102539, 48.07139892578125, 44.331155395507814, 41.4045295715332, 39.33646697998047, 37.34296646118164, 35.400821685791016, 33.900369262695314, 33.348822021484374, 31.542400741577147, 31.202974700927733, 30.48192138671875, 29.650181579589844, 28.757819366455077, 27.80408477783203, 27.575251388549805]), '4,32': (10.133618466059367, [155.29634704589844, 145.3312194824219, 137.19786682128907, 131.48546447753907, 123.81597442626953, 112.95846862792969, 97.97799224853516, 87.34897308349609, 78.85586853027344, 72.1830551147461, 66.30273895263672, 61.01434478759766, 56.52143478393555, 52.74603042602539, 49.484911346435545, 46.7810775756836, 44.25900726318359, 42.04575042724609, 40.03659591674805, 38.298457336425784, 37.20573272705078, 35.75520401000976, 34.51147308349609, 33.391503143310544, 32.49723663330078, 31.747182846069336, 31.245989990234374, 30.52946662902832, 29.71724967956543, 29.36984176635742]), '4,64': (17.952734462420146, [13070.372076416015, 154.6439208984375, 144.31059875488282, 139.47295837402345, 142.83912048339843, 129.51495819091798, 109.35470428466797, 76.17734832763672, 58.15738372802734, 55.3125602722168, 59.26879348754883, 44.049947357177736, 43.5503547668457, 41.8947639465332, 37.629093170166016, 36.88517608642578, 33.02313117980957, 31.24305953979492, 29.74343795776367, 29.06452331542969, 28.37405014038086, 27.65095329284668, 27.218424606323243, 27.323252868652343, 27.481272506713868, 25.631883239746095, 27.785328674316407, 27.314189910888672, 29.911963653564452, 34.3030818939209]), '5,32': (10.165281454722086, [155.71189575195314, 155.71177673339844, 155.7118408203125, 155.71182250976562, 155.71184997558595, 155.7117492675781, 155.71176147460938, 155.71172485351562, 155.71188659667968, 155.7118682861328, 155.71185302734375, 155.71185607910155, 155.71184387207032, 155.7117889404297, 155.71185302734375, 155.7118682861328, 155.7118347167969, 155.71186218261718, 155.71182250976562, 155.7118682861328, 155.7117462158203, 155.71185302734375, 155.71185607910155, 155.7118347167969, 155.711865234375, 155.71183166503906, 155.71188049316407, 155.7118377685547, 155.71187744140624, 155.71165161132814]), '5,64': (18.339521749814352, [155.71189575195314, 155.71177673339844, 155.7118408203125, 155.71182250976562, 155.71184997558595, 155.7117492675781, 155.71176147460938, 155.71172485351562, 155.71188659667968, 155.7118682861328, 155.71185302734375, 155.71185607910155, 155.71184387207032, 155.7117889404297, 155.71185302734375, 155.7118682861328, 155.7118347167969, 155.71186218261718, 155.71182250976562, 155.7118682861328, 155.7117462158203, 155.71185302734375, 155.71185607910155, 155.7118347167969, 155.711865234375, 155.71183166503906, 155.71188049316407, 155.7118377685547, 155.71187744140624, 155.71165161132814])}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4SqSwtoA5Zp",
        "outputId": "e5ed9a51-c71c-498d-d7d2-ccda583bd0f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import json \n",
        "all_losses_json = json.dumps(all_losses)\n",
        "print(all_losses_json)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\"1,32\": [6.71182476679484, [92.63471984863281, 58.182090759277344, 51.05170669555664, 49.26017761230469, 47.57956771850586, 46.67074813842773, 45.80816802978516, 45.33303298950195, 44.68516845703125, 44.414163970947264, 44.296163940429686, 43.73015213012695, 43.24689559936523, 42.91751480102539, 42.71629638671875, 42.5161849975586, 42.321920013427736, 42.12033309936523, 41.90849838256836, 41.80671081542969, 41.48017959594726, 41.455073547363284, 41.45417785644531, 41.237037658691406, 41.100476837158205, 41.06671981811523, 41.053828430175784, 40.90081100463867, 40.82514266967773, 40.80555114746094]], \"1,64\": [6.918313543001811, [88.46867523193359, 58.880174255371095, 52.02037124633789, 49.59053726196289, 47.85999221801758, 46.736235809326175, 45.758802795410155, 45.037732696533205, 44.19419174194336, 43.53841934204102, 42.87966613769531, 42.356974029541014, 41.88265380859375, 41.52345657348633, 41.28425521850586, 41.10011672973633, 41.025953674316405, 40.733621978759764, 40.5163818359375, 40.43647079467773, 40.161346435546875, 40.11470718383789, 40.11552505493164, 39.93864364624024, 39.94019622802735, 39.994902801513675, 39.90627822875977, 39.80110855102539, 39.72598419189453, 39.67598648071289]], \"2,32\": [9.312953273455301, [140.29572448730468, 110.4760238647461, 91.9915786743164, 83.58323364257812, 75.28921051025391, 65.85408096313476, 55.55426559448242, 49.978180694580075, 44.8772575378418, 39.60411148071289, 35.96235809326172, 33.120751571655276, 31.681095123291016, 30.97255516052246, 28.759826278686525, 27.314556121826172, 26.352624893188477, 25.824374389648437, 25.18336181640625, 24.580429077148438, 24.05251350402832, 23.564766311645506, 23.587179946899415, 23.070681381225587, 22.96668243408203, 23.48114356994629, 21.929568099975587, 22.98313331604004, 22.241170501708986, 22.30654373168945]], \"2,64\": [16.220271984736126, [124.25721893310546, 100.28298645019531, 91.0424072265625, 80.68925476074219, 74.72737274169921, 68.54922332763672, 60.88099975585938, 54.64442901611328, 49.648624420166016, 45.23415908813477, 41.55873260498047, 38.37748413085937, 35.64743881225586, 33.178591918945315, 32.772530746459964, 30.712491607666017, 29.09301643371582, 27.911982345581055, 27.223513412475587, 26.343770599365236, 25.54422378540039, 25.116579818725587, 24.621702575683592, 23.970185852050783, 23.480767059326173, 23.63583984375, 22.98143539428711, 22.68752670288086, 22.40080871582031, 21.99435501098633]], \"3,32\": [10.245744442939758, [144.04851989746095, 121.72943420410157, 110.48228759765625, 96.70335540771484, 81.39969482421876, 72.83882598876953, 66.1412124633789, 60.58987731933594, 55.63190841674805, 50.77169418334961, 47.03554916381836, 43.383749389648436, 40.19710464477539, 37.986751556396484, 35.87745666503906, 33.901065063476565, 32.20447196960449, 30.889654922485352, 29.813469314575194, 29.02189483642578, 28.172788619995117, 27.900343704223634, 27.04685821533203, 26.323174285888673, 26.376301956176757, 25.630674362182617, 24.819701766967775, 25.293637466430663, 24.132465744018553, 23.951994705200196]], \"3,64\": [17.92595005830129, [2930.0629699707033, 150.2129333496094, 148.4690155029297, 144.0926971435547, 140.09917907714845, 134.259423828125, 123.35794677734376, 107.01603393554687, 91.73970947265624, 81.00618286132813, 71.25652923583985, 65.74723052978516, 60.86029968261719, 58.83183212280274, 53.75423355102539, 48.07139892578125, 44.331155395507814, 41.4045295715332, 39.33646697998047, 37.34296646118164, 35.400821685791016, 33.900369262695314, 33.348822021484374, 31.542400741577147, 31.202974700927733, 30.48192138671875, 29.650181579589844, 28.757819366455077, 27.80408477783203, 27.575251388549805]], \"4,32\": [10.133618466059367, [155.29634704589844, 145.3312194824219, 137.19786682128907, 131.48546447753907, 123.81597442626953, 112.95846862792969, 97.97799224853516, 87.34897308349609, 78.85586853027344, 72.1830551147461, 66.30273895263672, 61.01434478759766, 56.52143478393555, 52.74603042602539, 49.484911346435545, 46.7810775756836, 44.25900726318359, 42.04575042724609, 40.03659591674805, 38.298457336425784, 37.20573272705078, 35.75520401000976, 34.51147308349609, 33.391503143310544, 32.49723663330078, 31.747182846069336, 31.245989990234374, 30.52946662902832, 29.71724967956543, 29.36984176635742]], \"4,64\": [17.952734462420146, [13070.372076416015, 154.6439208984375, 144.31059875488282, 139.47295837402345, 142.83912048339843, 129.51495819091798, 109.35470428466797, 76.17734832763672, 58.15738372802734, 55.3125602722168, 59.26879348754883, 44.049947357177736, 43.5503547668457, 41.8947639465332, 37.629093170166016, 36.88517608642578, 33.02313117980957, 31.24305953979492, 29.74343795776367, 29.06452331542969, 28.37405014038086, 27.65095329284668, 27.218424606323243, 27.323252868652343, 27.481272506713868, 25.631883239746095, 27.785328674316407, 27.314189910888672, 29.911963653564452, 34.3030818939209]], \"5,32\": [10.165281454722086, [155.71189575195314, 155.71177673339844, 155.7118408203125, 155.71182250976562, 155.71184997558595, 155.7117492675781, 155.71176147460938, 155.71172485351562, 155.71188659667968, 155.7118682861328, 155.71185302734375, 155.71185607910155, 155.71184387207032, 155.7117889404297, 155.71185302734375, 155.7118682861328, 155.7118347167969, 155.71186218261718, 155.71182250976562, 155.7118682861328, 155.7117462158203, 155.71185302734375, 155.71185607910155, 155.7118347167969, 155.711865234375, 155.71183166503906, 155.71188049316407, 155.7118377685547, 155.71187744140624, 155.71165161132814]], \"5,64\": [18.339521749814352, [155.71189575195314, 155.71177673339844, 155.7118408203125, 155.71182250976562, 155.71184997558595, 155.7117492675781, 155.71176147460938, 155.71172485351562, 155.71188659667968, 155.7118682861328, 155.71185302734375, 155.71185607910155, 155.71184387207032, 155.7117889404297, 155.71185302734375, 155.7118682861328, 155.7118347167969, 155.71186218261718, 155.71182250976562, 155.7118682861328, 155.7117462158203, 155.71185302734375, 155.71185607910155, 155.7118347167969, 155.711865234375, 155.71183166503906, 155.71188049316407, 155.7118377685547, 155.71187744140624, 155.71165161132814]]}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}