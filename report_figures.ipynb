{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from time import time, sleep\n",
    "\n",
    "from utils import *\n",
    "from custom_pca import custom_pca\n",
    "from video_loader import VideoLoader\n",
    "from autoencoders import *\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of PCA, PCAAE, OneH and TempConv reconstruction errors when encoding 30 sec of gray scale 256x256 video (R25_gray_scaled.mp4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_filename = 'data/R25_gray_scaled.mp4'\n",
    "\n",
    "def train_helper(model_key, base_model, model_args, video, lrs, models, num_epoch_tune=10, num_epoch=50):\n",
    "    iteration_per_epoch = int(video.duration_frames/video.batch_size)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print('Using device', device)\n",
    "    if device.type == 'cuda':\n",
    "        print(torch.cuda.get_device_name(0))\n",
    "\n",
    "    losses_tune = []\n",
    "    for lr in lrs:\n",
    "        if len(lrs) == 1:\n",
    "            losses_tune.append(0)\n",
    "            break\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        model = base_model(*model_args).to(device)\n",
    "        optimizer = Adam(model.parameters(), lr=lr)\n",
    "        for epoch in range(num_epoch_tune):\n",
    "            epoch_loss = 0\n",
    "            for frames in video:\n",
    "                frames = frames.to(device)\n",
    "                reconstructed = model(frames)\n",
    "                loss = crit(frames, reconstructed)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss += loss.item()\n",
    "        losses_tune.append(epoch_loss / iteration_per_epoch)\n",
    "        if len(losses_tune) >= 2 and losses_tune[-1] > losses_tune[-2]:\n",
    "            break\n",
    "    lr = lrs[np.argmin(losses_tune)]\n",
    "    print('Chosen learning rate:', lr)\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    model = base_model(*model_args).to(device)\n",
    "    optimizer = Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    t1 = time()\n",
    "    losses = []\n",
    "    for epoch in range(num_epoch):\n",
    "        epoch_loss = 0\n",
    "        for frames in video:\n",
    "            frames = frames.to(device)\n",
    "            reconstructed = model(frames)\n",
    "            loss = crit(frames, reconstructed)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        losses.append(epoch_loss / iteration_per_epoch)\n",
    "        if (epoch+1) % 3 == 0:\n",
    "            print(f'\\t Error at epoch {epoch+1}:', losses[-1])\n",
    "\n",
    "    model_dict = {\n",
    "        'model': model.state_dict(),\n",
    "        'epoch': num_epoch,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'lr': lr,\n",
    "        'losses_tune': losses_tune,\n",
    "        'lrs': lrs,\n",
    "        'losses': losses,\n",
    "        'epoch_time': (time()-t1)/num_epoch\n",
    "    }\n",
    "    models[model_key] = model_dict\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, model_key, models, meta):\n",
    "    reconstructed_train = video_train.reduce_latent(model, trans=False)\n",
    "    reconstructed_test = video_test.reduce_latent(model, trans=False)\n",
    "    original_frames_train_ = original_frames_train.numpy().reshape(-1, *video_train.sample_shape)\n",
    "    original_frames_test_  = original_frames_test.numpy().reshape(-1, *video_test.sample_shape)\n",
    "    models[key]['train_error'] = reconstruction_error(original_frames_train_, reconstructed_train.numpy())\n",
    "    models[key]['test_error'] = reconstruction_error(original_frames_test_, reconstructed_test.numpy())\n",
    "    print('Training error:', models[key]['train_error'])\n",
    "    print('Testing error:', models[key]['test_error'])\n",
    "    reconstructed_train_ = reconstructed_train.numpy().reshape(-1, video_train.height, video_train.width)\n",
    "\n",
    "video_train = VideoLoader(video_filename, duration=30, gray=True)\n",
    "video_test =  VideoLoader(video_filename, start=30, duration=10, gray=True)\n",
    "meta = {'w': video_train.width,\n",
    "        'h': video_train.height,\n",
    "        'fps': video_train.fps,\n",
    "        'bs': video_train.batch_size,\n",
    "        'gray': video_train.gray}\n",
    "original_frames_train = video_train.get_all_frames()\n",
    "original_frames_test = video_test.get_all_frames()\n",
    "num_epoch, num_epoch_tune = 40, 10\n",
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 50-PCAAE\n",
      "Using device cuda\n",
      "Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "############   PCA autoencoder   ############\n",
    "lrs = [1e-05, 5e-05, 1e-04]\n",
    "key = '50-PCAAE'\n",
    "print('\\nModel', key)\n",
    "video_train.sample_shape = video_test.sample_shape = (1, meta['h'], meta['w'])\n",
    "all_frames = video_train.get_all_frames()\n",
    "mean, std = torch.mean(all_frames), torch.std(all_frames)\n",
    "model = train_helper(key, PCAAutoEncoder, ((1, meta['w'], meta['h']), 50, mean, std), video_train,\n",
    "                           lrs, models, num_epoch_tune=15)\n",
    "model.to(torch.device('cpu'))\n",
    "evaluate_model(model, key, models, meta)\n",
    "\n",
    "############ One hidden layer AE ############\n",
    "key = '10-OneHAE'\n",
    "print('\\nModel', key)\n",
    "lrs = [5e-4, 1e-3]\n",
    "video_train.sample_shape = video_test.sample_shape = (1, meta['h'], meta['w'])\n",
    "model = train_helper(key, OneHAutoEncoder, ((1, meta['h'], meta['w']), 10), video_train,\n",
    "                          lrs, models)\n",
    "model.to(torch.device('cpu'))\n",
    "evaluate_model(model, key, models, meta)\n",
    "\n",
    "############   Temporal Conv AE   ############\n",
    "key = 'TempConvAE'\n",
    "print('\\nModel', key)\n",
    "video_train.sample_shape = video_test.sample_shape = (1, 16, meta['h'], meta['w'])\n",
    "model = train_helper(key, TemporalConvAE, (1, 2, 32), video_train, lrs, models)\n",
    "model.to(torch.device('cpu'))\n",
    "evaluate_model(model, key, models, meta)\n",
    "\n",
    "############  10-Temporal Conv AE  ############\n",
    "key = '10-TempConvAE'\n",
    "print('\\nModel', key)\n",
    "video_train.sample_shape = video_test.sample_shape = (1, 16, meta['h'], meta['w'])\n",
    "model = train_helper(key, TemporalConvAE, (1, 2, 32, 10), video_train,\n",
    "                                   lrs, models)\n",
    "model.to(torch.device('cpu'))\n",
    "evaluate_model(model, key, models, meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models['10-OneHAE']['losses_tune'], #models['10-OneHAE']['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = [m['losses'] for m in models.values()]\n",
    "max_epoch = max([m['epoch'] for m in models.values()])\n",
    "losses.append([8.126883]*max_epoch)\n",
    "xs = [range(1, m['epoch']+1) for m in models.values()] + [range(1, max_epoch+1)]\n",
    "labels = [l for l in models.keys()] + ['PCA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(xs, losses, labels=labels,\n",
    "    xlabel='Epoch', ylabel='Error', yrange=(0, 70))\n",
    "plt.savefig('data_generated/report_figures/reconstruction_error_comparison_pca_oneh_tempconv.png')\n",
    "for k, m in models.items():\n",
    "    print('Final error for %s:' % k)\n",
    "    print('\\tTraining:', m['train_error'])\n",
    "    print('\\tTesting:', m['test_error'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TempConv, latent dimension comparison. Computed in week5 (testing_colab.ipynb). Use 10 seconds of R25_gray_scaled.mp4 video scaled to 256x256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_generated/all_losses_from_colab_2.json', 'r') as fp:\n",
    "    all_losses = json.load(fp)\n",
    "\n",
    "ys = [l for _, l in all_losses.values()]\n",
    "labels = [l for l in all_losses.keys()]\n",
    "\n",
    "plot(range(1, 41), ys, labels=labels, yrange=(0, 40),\n",
    "     xlabel='Epoch', ylabel='Loss')\n",
    "plt.savefig('data_generated/report_figures/latent_dimension_comparison_tempconv.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TempConv, depth and number of channels comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_filename = 'data/R25_gray_scaled.mp4'\n",
    "video = VideoLoader(video_filename, duration=10, gray=True, randit=True)\n",
    "num_epoch, num_epoch_tune = 30, 10\n",
    "iteration_per_epoch = int(video.duration_frames/video.batch_size)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device', device)\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "\n",
    "all_losses = {}\n",
    "lrs = {1: [1e-4, 5e-4, 0.001, 0.005],\n",
    "       2: [1e-4, 5e-4, 0.001],\n",
    "       3: [1e-4, 5e-4, 0.001],\n",
    "       4: [1e-5, 5e-5, 1e-4, 5e-4],\n",
    "       5: [1e-5, 5e-5, 1e-4, 5e-4]}\n",
    "for nlayers in range(1, 6):\n",
    "    for layerchans in [4, 8, 12, 32, 64]:\n",
    "        total_time_start = time()\n",
    "        print(f'Model with {nlayers} layer with {layerchans} channels:')\n",
    "\n",
    "        losses_tune = []\n",
    "        for lr in lrs[nlayers]:\n",
    "            torch.manual_seed(seed)\n",
    "            np.random.seed(seed)\n",
    "            model = TemporalConvAE_week5(1, nlayers, layerchans).to(device)\n",
    "            optimizer = Adam(model.parameters(), lr=lr)\n",
    "            for epoch in range(num_epoch_tune):\n",
    "                epoch_loss = 0\n",
    "                for frames in video:\n",
    "                    frames = frames.view(-1, 1, video.batch_size, video.height, video.width).to(device)\n",
    "                    reconstructed = model(frames)\n",
    "                    loss = crit(frames, reconstructed)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    epoch_loss += loss.item()\n",
    "            losses_tune.append(epoch_loss / iteration_per_epoch)\n",
    "        lr = lrs[nlayers][np.argmin(losses_tune)]\n",
    "        print('Chosen learning rate:', lr)\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        model = TemporalConvAE_week5(1, nlayers, layerchans).to(device)\n",
    "        optimizer = Adam(model.parameters(), lr=lr)\n",
    "\n",
    "        t1 = time()\n",
    "        losses = []\n",
    "        for epoch in range(num_epoch):\n",
    "            epoch_loss = 0\n",
    "            for frames in video:\n",
    "                frames = frames.view(-1, 1, video.batch_size, video.height, video.width).to(device)\n",
    "                reconstructed = model(frames)\n",
    "                loss = crit(frames, reconstructed)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss += loss.item()\n",
    "            losses.append(epoch_loss / iteration_per_epoch)\n",
    "            if (epoch+1) % 3 == 0:\n",
    "                print(f'\\t Error at epoch {epoch+1}:', losses[-1])\n",
    "        all_losses[f'{nlayers},{layerchans}'] = ((time()-t1)/num_epoch, losses)\n",
    "        print('Total time for model:', sec2string(time()-total_time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_losses = dict(sorted(all_losses.items()))\n",
    "all_losses = {f'{l},{c}': all_losses[f'{l},{c}'] for l in [1,2,3,4,5] for c in [4,8,12,32,64]}\n",
    "\n",
    "ys = [t[1] for t in all_losses.values()]\n",
    "plot(range(1, num_epoch+1), ys, labels=all_losses.keys(), xlabel='Epoch', ylabel='Error',\n",
    "     title='Evolution of loss, optimized lr, legend: nlayers,nchannels',\n",
    "     styles=['C'+str(c)+'-'+s for c in [0,1,2,3,6] for s in ['s','o','^','.','']],\n",
    "     yrange=(20, 60), figsize=(20, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nlayers in range(1, 6):\n",
    "    for layerchans in [4, 8, 12, 32, 64]:\n",
    "        print(nlayers, layerchans)\n",
    "        model = TemporalConvAE_week5(1, nlayers, layerchans).to(device)\n",
    "        for frames in video:\n",
    "            frames = frames.view(-1, 1, video.batch_size, video.height, video.width).to(device)\n",
    "            reconstructed = model(frames)\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
