Semester project info:
- Title: Learning the Dynamics of Complex and High-dimensional Time-series (too vague)
- Teacher: Benjamin Bejar Haro
- Assistant: ???
- Keywords: Tic disorder, Linear Dynamical Systems, Auto-encoder, Deep-learning, Image Stream processin, Activity recognition
- Student's comment:

Week -1 (1.08 - 8.09):
Asked to begin the setup of the environment for a basic LDS framework that uses PCA to go from signal space to low-dimensional representation. Because of the very high-dimensionnality of the signal -> incrementalPCA from sklearn. For this setup, need to create a class that load portions of video (chunks composed of a small numbers of frames) and convert it to tensor (so that it can be feed to the PCA model).

I dived into the Doretto's paper to understand how we will use the LDS formalism here. I focused on the loading of the video as it is the main challenge in terms of code for this part (at least until the training of the transition matrix for the low-dimensional representation of the signal). Problem: can't even load more than 1 minute of video without it to fill all my 20GB of RAM. Possible solutions I look into are preprocess the video into chunks converted to tensor written to disk and find a way to load a portion of video, convert it, feed it to PCA, free it, repeat until a PCA model for each video has been created so that we can convert this video.

Goal until the meeting with all the team on this Thursday: find how we will load those videos and code an example of loading -> create PCA -> convert it -> write it to see how that affect the video on a small clip (10-20 sec).

Week 0 (8.09 - 15.09):
- Done the loading -> PCA -> inverse_PCA -> writting for 20s of grayscale video with quality 960x540. Cannot be done in one go for the same video in color.
- Added VideoIterator that permit to iterate over the video so that we can use partial_fit of IncrementalPCA. This avoided the RAM to overload. This permits to transform the colored video in 4 times more time than the gray scale (3 times more dimensions so it seems to scale pretty well).

- Bottleneck is clearly the PCA fitting time, may not be normal tthat it takes so long -> comparison to SVD. Problem is that the SVD cannot be computed iteratively (no?). Tried to load a video of 22min, without feeding it to PCA to see if it scales and yes it works.

Week 1:
Goals of the week:
- Better comparison of the fitting time of PCA between iterative and all at once
- Find why the video is saturated after PCA compression and correct it
- Write  a function that scales on video to asked quality (will be useful later to reduce dim)
- Find a way to go from SVD to a PCA model so that with an SVD we can reduce the dim (and back)
- Adapt the SVD decomposition so that it can be computed to longer video (take N random frames with N fixed no matter the video duration to estimate the SVD)
- Compare quality of reconstruction between approximation of the SVD and exact SVD (and PCA?)

Comparison of fitting time:
Loading and fitting time fro grayscale, 960x540, 20s video reduced to 20 components:
- All at once: 2m6s
- Iterator: 2m18s

TAG: week0
