Semester project info:
- Title: Learning the Dynamics of Complex and High-dimensional Time-series (too vague)
- Teacher: Benjamin Bejar Haro
- Assistant: ???
- Keywords: Tic disorder, Linear Dynamical Systems, Auto-encoder, Deep-learning, Image Stream processin, Activity recognition
- Student's comment:

Week -1 (1.08 - 8.09):
Asked to begin the setup of the environment for a basic LDS framework that uses PCA to go from signal space to low-dimensional representation. Because of the very high-dimensionnality of the signal -> incrementalPCA from sklearn. For this setup, need to create a class that load portions of video (chunks composed of a small numbers of frames) and convert it to tensor (so that it can be feed to the PCA model).

I dived into the Doretto's paper to understand how we will use the LDS formalism here. I focused on the loading of the video as it is the main challenge in terms of code for this part (at least until the training of the transition matrix for the low-dimensional representation of the signal). Problem: can't even load more than 1 minute of video without it to fill all my 20GB of RAM. Possible solutions I look into are preprocess the video into chunks converted to tensor written to disk and find a way to load a portion of video, convert it, feed it to PCA, free it, repeat until a PCA model for each video has been created so that we can convert this video.

Goal until the meeting with all the team on this Thursday: find how we will load those videos and code an example of loading -> create PCA -> convert it -> write it to see how that affect the video on a small clip (10-20 sec).

Week 0 (8.09 - 15.09):
- Done the loading -> PCA -> inverse_PCA -> writting for 20s of grayscale video with quality 960x540. Cannot be done in one go for the same video in color.
- Added VideoIterator that permit to iterate over the video so that we can use partial_fit of IncrementalPCA. This avoided the RAM to overload. This permits to transform the colored video in 4 times more time than the gray scale (3 times more dimensions so it seems to scale pretty well).

- Bottleneck is clearly the PCA fitting time, may not be normal tthat it takes so long -> comparison to SVD. Problem is that the SVD cannot be computed iteratively (no?). Tried to load a video of 22min, without feeding it to PCA to see if it scales and yes it works.

Week 1:
Goals of the week:
- Better comparison of the fitting time of PCA between iterative and all at once
- Find why the video is saturated after PCA compression and correct it
- Write  a function that scales on video to asked quality (will be useful later to reduce dim)
- Find a way to go from SVD to a PCA model so that with an SVD we can reduce the dim (and back)
- Adapt the SVD decomposition so that it can be computed to longer video (take N random frames with N fixed no matter the video duration to estimate the SVD)
- Compare quality of reconstruction between approximation of the SVD and exact SVD (and PCA?)

Comparison of PCA fitting time:
Loading and fitting time fro grayscale, 960x540, 20s video reduced to 20 components:
- All at once: 2m6s
- Iterator: 2m18s

TAG: week0

- Corrected saturation
- Scaling included in the VideoLoader contructor (optional argument)
- PCA using svd done with the custom_pca class
- For longer video, read_video (with the random argument) can be used to load a given amount of random frames from a video. That can be used to fit the custom PCA model and then the whole video can be converted using this object. (Not in this function anymore, directly in the VideoLoader)
- Comparison for quality of reconstruction and computational time for 20s 960x540 (color):

Model:			Custom PCA	Custom PCA	Custom PCA	Custom PCA	Custom PCA	PCA_64		PCA_128
Frames:			100%				50%					25%					10%					5%					100%			100%
Fit time:		1m4s				37s					15s					7s					5.9s				5m32s			6m22s
Trans time:	42s					15s					15s					15s					15s					32s				39s
l2-error:		8.5					41.6				48.2				49.2, 73		271, 93			32.8			32.8

So the loss of the first half of frame hurt, but after it's mostly the variance that rises. SVD is way faster than PCA, and gives better result when using all frames (the partial fitting is not equivalent to a full PCA model).
Also, the transformation is faster when done in batches.

Meeting re-scheduled
Registration to project's done (Assistant: None)

TAG: week1

Week 2:
Goals:
- Write a framework for (L)DS and see how to optimize it
- Make more experiments as to see how the reconstruction error evolve with the number of components

5 minutes, grayscale, 256x256, 0.5 frames to fit:
ncomp					10		25		50		100		150
fit time			30.8	33.4	36		50.8	72.3
trans time		10.9	11.1	12.5	14.4	18.3
error					8.45	7.98	7.45	6.71	6.16

10 minutes, grayscale, 256x256, 0.2 frames to fit:
ncomp					10		25		50		100		150
fit time			13		13		17		22		32
trans time		21		23		26		32		35
error					8.62	8.1		7.59	6.85	6.31

10 minutes, grayscale, 256x256 (scaled at runtime), 0.2 frames to fit:
ncomp					10		25
fit time			44		46
trans time		84		85
error					8.63	8.13
